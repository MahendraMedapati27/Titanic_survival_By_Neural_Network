{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import MeanSquaredError,BinaryCrossentropy\n",
    "from tensorflow.keras.activations import sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# ignores (suppresses) all warnings raised during the execution of your Python code.\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_train_set = pd.read_csv(r'C:\\Users\\Hp\\OneDrive\\Desktop\\Kaggle work\\titanic\\train.csv')\n",
    "test_set = pd.read_csv(r'C:\\Users\\Hp\\OneDrive\\Desktop\\Kaggle work\\titanic\\test.csv')\n",
    "Y_test = pd.read_csv(r'C:\\Users\\Hp\\OneDrive\\Desktop\\Kaggle work\\titanic\\gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ini_train_set.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "ini_train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ini_train_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training data shape\n",
    "ini_train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test data shape\n",
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop cabin and ticket from the training data set\n",
    "ini_train_set.drop(['Cabin','Ticket'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop cabin and ticket from the test data set\n",
    "test_set.drop(['Cabin', 'Ticket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.472826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.242363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Survived\n",
       "0       1  0.629630\n",
       "1       2  0.472826\n",
       "2       3  0.242363"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#groups the DataFrame ini_train_set by the 'Pclass' column and then calculates the mean of the 'Survived' column for each group. \n",
    "ini_train_set.groupby(['Pclass'], as_index=False)['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Survived\n",
       "0  female  0.742038\n",
       "1    male  0.188908"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#groups the DataFrame ini_train_set by the 'Sex' column and then calculates the mean of the 'Survived' column for each group. \n",
    "ini_train_set.groupby(['Sex'], as_index=False)['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.345395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.535885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.464286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SibSp  Survived\n",
       "0      0  0.345395\n",
       "1      1  0.535885\n",
       "2      2  0.464286\n",
       "3      3  0.250000\n",
       "4      4  0.166667\n",
       "5      5  0.000000\n",
       "6      8  0.000000"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#groups the DataFrame ini_train_set by the 'SibSp' column and then calculates the mean of the 'Survived' column for each group. \n",
    "ini_train_set.groupby(['SibSp'], as_index=False)['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parch</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.343658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.550847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parch  Survived\n",
       "0      0  0.343658\n",
       "1      1  0.550847\n",
       "2      2  0.500000\n",
       "3      3  0.600000\n",
       "4      4  0.000000\n",
       "5      5  0.200000\n",
       "6      6  0.000000"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#groups the DataFrame ini_train_set by the 'Parch' column and then calculates the mean of the 'Survived' column for each group. \n",
    "ini_train_set.groupby(['Parch'], as_index=False)['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>0.553571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q</td>\n",
       "      <td>0.389610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>0.336957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Embarked  Survived\n",
       "0        C  0.553571\n",
       "1        Q  0.389610\n",
       "2        S  0.336957"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#groups the DataFrame ini_train_set by the 'Embarked' column and then calculates the mean of the 'Survived' column for each group. \n",
    "ini_train_set.groupby(['Embarked'], as_index=False)['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Age histogram grouped by Survive \n",
    "# Set the style of the visualization\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Create a histogram of the 'Age' variable split by 'Survived'\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(data=ini_train_set, x='Age', hue='Survived', bins=200, alpha=0.6)\n",
    "plt.title('Histogram of Age by Survived')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Survived', labels=['Yes', 'No'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Age histogram grouped by Survive \n",
    "# Set the style of the visualization\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Create a histogram of the 'Age' variable split by 'Survived'\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(data=ini_train_set, x='Fare', hue='Survived', bins=100, alpha=0.6)\n",
    "plt.title('Histogram of Fare by Survived')\n",
    "plt.xlabel('Fare')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Survived', labels=['Yes', 'No'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Fare             0\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no of empty rows w.r.t columns in training set\n",
    "ini_train_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId     0\n",
       "Pclass          0\n",
       "Name            0\n",
       "Sex             0\n",
       "Age            86\n",
       "SibSp           0\n",
       "Parch           0\n",
       "Fare            1\n",
       "Embarked        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no of empty rows w.r.t columns in test set\n",
    "test_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the empty spaces in the age column with the median value of the column\n",
    "ini_train_set['Age'].fillna(ini_train_set['Age'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the empty spaces in the embarked column with the mode value of the column\n",
    "ini_train_set['Embarked'].fillna(ini_train_set['Embarked'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the empty spaces in the age column with the median value of the column\n",
    "test_set['Age'].fillna(test_set['Age'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the empty spaces in the fare column with the median value of the column\n",
    "test_set['Fare'].fillna(test_set['Fare'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Fare           0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ini_train_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Fare           0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing male with 0 and female with 1 in training set since female survived the most\n",
    "ini_train_set.replace({'Sex':{'male':0,'female':1}},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing male with 0 and female with 1 in test set since female survived the most\n",
    "test_set.replace({'Sex':{'male':0,'female':1}},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the c with 1 and Q with 0 and S with 0 since C has survived more in training set\n",
    "ini_train_set.replace({'Embarked':{'C':1,'Q':0,'S':0}},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the c with 1 and Q with 0 and S with 0 since C has survived more in test set\n",
    "test_set.replace({'Embarked':{'C':1,'Q':0,'S':0}},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the parch 0,1,2,3,4,5,6 with 0,1,0,1,0,0,0 respectively sice parch 1,3 survived the most in training set\n",
    "ini_train_set.replace({'Parch': {0: 0, 1: 1, 2: 0, 3: 1, 4: 0, 5: 0, 6: 0}}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the parch 0,1,2,3,4,5,6 with 0,1,0,1,0,0,0 respectively in test set\n",
    "test_set.replace({'Parch': {0: 0, 1: 1, 2: 0, 3: 1, 4: 0, 5: 0, 6: 0}}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repalcing the pclass 1,2,3 with 1,0,0 respectively since pclass 1 survived the most in training set\n",
    "ini_train_set.replace({'Pclass':{1:1, 2:0, 3:0}},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the pclass 1,2,3 with 1,0,0 respectively in the test set same as the training set\n",
    "test_set.replace({'Pclass':{1:1, 2:0, 3:0}},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing sibsp 0,1,2,3,4,5,8 with 0,1,1,0,0,0,0 respectively since sibsp 1,2 survived the most in the training set \n",
    "ini_train_set.replace({'SibSp':{0:0,1:1, 2:1, 3:0,4:0,5:0,8:0}},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing sibsp 0,1,2,3,4,5,8 with 0,1,1,0,0,0,0 respectively in the test set same as training set\n",
    "test_set.replace({'SibSp':{0:0,1:1, 2:1, 3:0,4:0,5:0,8:0}},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values in the 'Age' column with 1 where the age is less than or equal to 15 or greater than 65 in training set \n",
    "ini_train_set.loc[(ini_train_set['Age'] <=15) | (ini_train_set['Age']>=65) ,'Age'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values in the 'Age' column with 1 where the age is less than or equal to 15 or greater than 65\n",
    "test_set.loc[(test_set['Age'] <= 15)| (ini_train_set['Age']>=65), 'Age'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repalce values in the age column with 0 if the age is greater than 15\n",
    "ini_train_set.loc[(ini_train_set['Age'] > 15), 'Age'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repalce values in the age column with 0 if the age is greater than 15\n",
    "test_set.loc[(test_set['Age'] > 15), 'Age'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11    0.0\n",
      "12    0.0\n",
      "13    0.0\n",
      "14    1.0\n",
      "15    0.0\n",
      "16    1.0\n",
      "17    0.0\n",
      "18    0.0\n",
      "19    0.0\n",
      "20    0.0\n",
      "21    0.0\n",
      "22    1.0\n",
      "23    0.0\n",
      "24    1.0\n",
      "25    0.0\n",
      "26    0.0\n",
      "27    0.0\n",
      "28    0.0\n",
      "29    0.0\n",
      "30    0.0\n",
      "31    0.0\n",
      "32    0.0\n",
      "33    1.0\n",
      "34    0.0\n",
      "35    0.0\n",
      "36    0.0\n",
      "37    0.0\n",
      "38    0.0\n",
      "39    1.0\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(ini_train_set.Age[11:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the values in the fare column with 0 if the fare is less than 50\n",
    "ini_train_set.loc[(ini_train_set['Fare'] <50), 'Fare'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the values in the fare column with 0 if the fare is less than 50\n",
    "test_set.loc[(test_set['Fare'] < 50), 'Fare'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the values in the fare column with 1 if the values are greater than equal to 50\n",
    "ini_train_set.loc[(ini_train_set['Fare'] >=50), 'Fare'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the values in the fare column with 1 if the values are greater than equal to 50\n",
    "test_set.loc[(test_set['Fare'] >= 50), 'Fare'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     1.0\n",
      "2     0.0\n",
      "3     1.0\n",
      "4     0.0\n",
      "5     0.0\n",
      "6     1.0\n",
      "7     0.0\n",
      "8     0.0\n",
      "9     0.0\n",
      "10    0.0\n",
      "11    0.0\n",
      "12    0.0\n",
      "13    0.0\n",
      "14    0.0\n",
      "15    0.0\n",
      "16    0.0\n",
      "17    0.0\n",
      "18    0.0\n",
      "19    0.0\n",
      "20    0.0\n",
      "21    0.0\n",
      "22    0.0\n",
      "23    0.0\n",
      "24    0.0\n",
      "25    0.0\n",
      "26    0.0\n",
      "27    1.0\n",
      "28    0.0\n",
      "29    0.0\n",
      "30    0.0\n",
      "31    1.0\n",
      "32    0.0\n",
      "33    0.0\n",
      "34    1.0\n",
      "35    1.0\n",
      "36    0.0\n",
      "37    0.0\n",
      "38    0.0\n",
      "39    0.0\n",
      "Name: Fare, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(ini_train_set.Fare[1:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = ['Sex', 'Embarked', 'Parch', 'Pclass', 'SibSp','Age','Fare']  # List of feature column names\n",
    "Y = ini_train_set['Survived']  # Target variable\n",
    "X = ini_train_set[X_]  # Feature variables\n",
    "X_test = test_set[X_]  # test feature variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting data into training set and cross validation set\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, Y, test_size=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scaling (standardizing) the features in the training set X_train and fitting the scaler to it\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transforming the cross-validation set X_cv using the scaler fitted on the training set\n",
    "X_cv = scaler.transform(X_cv)\n",
    "\n",
    "# Transforming the test set X_test using the same scaler\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((882, 7), (9, 7), (882,), (9,), (418, 7))"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the shapes of various datasets to check dimensions\n",
    "\n",
    "# Output the shape of the training set X_train\n",
    "X_train.shape\n",
    "\n",
    "# Output the shape of the cross-validation set X_cv\n",
    "X_cv.shape\n",
    "\n",
    "# Output the shape of the training labels y_train\n",
    "y_train.shape\n",
    "\n",
    "# Output the shape of the cross-validation labels y_cv\n",
    "y_cv.shape\n",
    "\n",
    "# Output the shape of the test set X_test\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Sequential model using Keras API\n",
    "model = tf.keras.Sequential([\n",
    "    # First hidden layer with 256 neurons, ReLU activation function, and L2 regularization\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    \n",
    "    # Dropout layer with a dropout rate of 0.5 to prevent overfitting\n",
    "    \n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    # Second hidden layer with 128 neurons, ReLU activation function, and L2 regularization\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    \n",
    "    # Dropout layer with a dropout rate of 0.5\n",
    "    \n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    # Third hidden layer with 64 neurons, ReLU activation function, and L2 regularization\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    \n",
    "    # Dropout layer with a dropout rate of 0.5\n",
    "    \n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    # Fourth hidden layer with 32 neurons, ReLU activation function, and L2 regularization\n",
    "    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    \n",
    "    # Dropout layer with a dropout rate of 0.5\n",
    "    \n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    # Output layer with 1 neuron and sigmoid activation function for binary classification\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with specified optimizer, loss function, and evaluation metrics\n",
    "model.compile(\n",
    "    optimizer='adam',               # Adam optimizer, which is commonly used for training neural networks\n",
    "    loss='binary_crossentropy',    # Binary cross-entropy loss function for binary classification tasks\n",
    "    metrics=['accuracy']           # Evaluation metric to monitor during training, accuracy in this case\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7706 - loss: 0.5497\n",
      "Epoch 2/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7822 - loss: 0.5276\n",
      "Epoch 3/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7740 - loss: 0.5393\n",
      "Epoch 4/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7871 - loss: 0.5342\n",
      "Epoch 5/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7933 - loss: 0.5038\n",
      "Epoch 6/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7889 - loss: 0.5240\n",
      "Epoch 7/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7893 - loss: 0.5072\n",
      "Epoch 8/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7788 - loss: 0.5403\n",
      "Epoch 9/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8102 - loss: 0.5063\n",
      "Epoch 10/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7749 - loss: 0.5339\n",
      "Epoch 11/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7609 - loss: 0.5602\n",
      "Epoch 12/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7952 - loss: 0.5444\n",
      "Epoch 13/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7537 - loss: 0.5545\n",
      "Epoch 14/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7746 - loss: 0.5384\n",
      "Epoch 15/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7931 - loss: 0.5233\n",
      "Epoch 16/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7895 - loss: 0.5183\n",
      "Epoch 17/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7814 - loss: 0.5538\n",
      "Epoch 18/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7784 - loss: 0.5520\n",
      "Epoch 19/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7764 - loss: 0.5136\n",
      "Epoch 20/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7610 - loss: 0.5415\n",
      "Epoch 21/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8009 - loss: 0.5080\n",
      "Epoch 22/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7877 - loss: 0.5115\n",
      "Epoch 23/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7740 - loss: 0.5269\n",
      "Epoch 24/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7657 - loss: 0.5450\n",
      "Epoch 25/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7533 - loss: 0.5354\n",
      "Epoch 26/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7908 - loss: 0.5384\n",
      "Epoch 27/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7826 - loss: 0.5552\n",
      "Epoch 28/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7837 - loss: 0.5346\n",
      "Epoch 29/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7777 - loss: 0.5302\n",
      "Epoch 30/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8060 - loss: 0.5403\n",
      "Epoch 31/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7868 - loss: 0.5576\n",
      "Epoch 32/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8080 - loss: 0.5179\n",
      "Epoch 33/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7857 - loss: 0.5237\n",
      "Epoch 34/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7688 - loss: 0.5512\n",
      "Epoch 35/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7731 - loss: 0.5485\n",
      "Epoch 36/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7771 - loss: 0.5310\n",
      "Epoch 37/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7719 - loss: 0.5457\n",
      "Epoch 38/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7739 - loss: 0.5408\n",
      "Epoch 39/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7806 - loss: 0.5382\n",
      "Epoch 40/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7751 - loss: 0.5678\n",
      "Epoch 41/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7989 - loss: 0.5044\n",
      "Epoch 42/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7806 - loss: 0.5284\n",
      "Epoch 43/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7933 - loss: 0.5129\n",
      "Epoch 44/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7978 - loss: 0.5291\n",
      "Epoch 45/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7955 - loss: 0.5147\n",
      "Epoch 46/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8030 - loss: 0.5076\n",
      "Epoch 47/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7724 - loss: 0.5215\n",
      "Epoch 48/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7662 - loss: 0.5616\n",
      "Epoch 49/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8151 - loss: 0.4998\n",
      "Epoch 50/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7872 - loss: 0.5200\n",
      "Epoch 51/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7708 - loss: 0.5516\n",
      "Epoch 52/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7827 - loss: 0.5246\n",
      "Epoch 53/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7865 - loss: 0.5207\n",
      "Epoch 54/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7618 - loss: 0.5433\n",
      "Epoch 55/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7775 - loss: 0.5094\n",
      "Epoch 56/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7787 - loss: 0.5185\n",
      "Epoch 57/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7828 - loss: 0.5205\n",
      "Epoch 58/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7724 - loss: 0.5392\n",
      "Epoch 59/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7871 - loss: 0.5367\n",
      "Epoch 60/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7652 - loss: 0.5367\n",
      "Epoch 61/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.5424\n",
      "Epoch 62/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7780 - loss: 0.5395\n",
      "Epoch 63/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7704 - loss: 0.5474\n",
      "Epoch 64/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7881 - loss: 0.5382\n",
      "Epoch 65/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7728 - loss: 0.5689\n",
      "Epoch 66/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 0.5103\n",
      "Epoch 67/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7632 - loss: 0.5433\n",
      "Epoch 68/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7988 - loss: 0.5337\n",
      "Epoch 69/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7796 - loss: 0.5175\n",
      "Epoch 70/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7633 - loss: 0.5625\n",
      "Epoch 71/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7825 - loss: 0.5405\n",
      "Epoch 72/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7630 - loss: 0.5733\n",
      "Epoch 73/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7997 - loss: 0.5183\n",
      "Epoch 74/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7634 - loss: 0.5510\n",
      "Epoch 75/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7664 - loss: 0.5319\n",
      "Epoch 76/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7544 - loss: 0.5460\n",
      "Epoch 77/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7725 - loss: 0.5349\n",
      "Epoch 78/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7556 - loss: 0.5526\n",
      "Epoch 79/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7751 - loss: 0.5320\n",
      "Epoch 80/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7309 - loss: 0.5566\n",
      "Epoch 81/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8232 - loss: 0.5104\n",
      "Epoch 82/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7624 - loss: 0.5485\n",
      "Epoch 83/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7870 - loss: 0.5327\n",
      "Epoch 84/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7643 - loss: 0.5303\n",
      "Epoch 85/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7954 - loss: 0.5220\n",
      "Epoch 86/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7904 - loss: 0.5055\n",
      "Epoch 87/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7514 - loss: 0.5545\n",
      "Epoch 88/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8124 - loss: 0.5110\n",
      "Epoch 89/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7757 - loss: 0.5363\n",
      "Epoch 90/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7616 - loss: 0.5618\n",
      "Epoch 91/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7857 - loss: 0.5447\n",
      "Epoch 92/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7863 - loss: 0.5282\n",
      "Epoch 93/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7760 - loss: 0.5577\n",
      "Epoch 94/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8109 - loss: 0.5025\n",
      "Epoch 95/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7360 - loss: 0.5718\n",
      "Epoch 96/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7838 - loss: 0.5228\n",
      "Epoch 97/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7610 - loss: 0.5561\n",
      "Epoch 98/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7665 - loss: 0.5488\n",
      "Epoch 99/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7736 - loss: 0.5431\n",
      "Epoch 100/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8229 - loss: 0.5033\n",
      "Epoch 101/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7642 - loss: 0.5512\n",
      "Epoch 102/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7640 - loss: 0.5331\n",
      "Epoch 103/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7577 - loss: 0.5632\n",
      "Epoch 104/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8116 - loss: 0.4968\n",
      "Epoch 105/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7907 - loss: 0.5484\n",
      "Epoch 106/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7520 - loss: 0.5548\n",
      "Epoch 107/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7429 - loss: 0.5911\n",
      "Epoch 108/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7658 - loss: 0.5641\n",
      "Epoch 109/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7786 - loss: 0.5323\n",
      "Epoch 110/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7808 - loss: 0.5389\n",
      "Epoch 111/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7891 - loss: 0.5203\n",
      "Epoch 112/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8011 - loss: 0.5163\n",
      "Epoch 113/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7591 - loss: 0.5603\n",
      "Epoch 114/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7528 - loss: 0.5453\n",
      "Epoch 115/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7819 - loss: 0.5193\n",
      "Epoch 116/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7927 - loss: 0.5227\n",
      "Epoch 117/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7541 - loss: 0.5566\n",
      "Epoch 118/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7951 - loss: 0.5417\n",
      "Epoch 119/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7668 - loss: 0.5340\n",
      "Epoch 120/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7790 - loss: 0.5406\n",
      "Epoch 121/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7855 - loss: 0.5132\n",
      "Epoch 122/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7888 - loss: 0.5143\n",
      "Epoch 123/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7657 - loss: 0.5563\n",
      "Epoch 124/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7846 - loss: 0.5316\n",
      "Epoch 125/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7904 - loss: 0.5253\n",
      "Epoch 126/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7988 - loss: 0.5025\n",
      "Epoch 127/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7616 - loss: 0.5484\n",
      "Epoch 128/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7797 - loss: 0.5360\n",
      "Epoch 129/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7628 - loss: 0.5482\n",
      "Epoch 130/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7980 - loss: 0.5180\n",
      "Epoch 131/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7859 - loss: 0.5395\n",
      "Epoch 132/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7948 - loss: 0.5130\n",
      "Epoch 133/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7939 - loss: 0.5287\n",
      "Epoch 134/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7665 - loss: 0.5313\n",
      "Epoch 135/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8083 - loss: 0.4889\n",
      "Epoch 136/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7850 - loss: 0.5412\n",
      "Epoch 137/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7818 - loss: 0.5277\n",
      "Epoch 138/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7661 - loss: 0.5480\n",
      "Epoch 139/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7596 - loss: 0.5334\n",
      "Epoch 140/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7791 - loss: 0.5192\n",
      "Epoch 141/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7946 - loss: 0.5163\n",
      "Epoch 142/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7877 - loss: 0.5478\n",
      "Epoch 143/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7830 - loss: 0.5269\n",
      "Epoch 144/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7175 - loss: 0.5794\n",
      "Epoch 145/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7629 - loss: 0.5526\n",
      "Epoch 146/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7521 - loss: 0.5454\n",
      "Epoch 147/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7846 - loss: 0.5253\n",
      "Epoch 148/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8056 - loss: 0.5129\n",
      "Epoch 149/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7665 - loss: 0.5303\n",
      "Epoch 150/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7841 - loss: 0.5381\n",
      "Epoch 151/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8082 - loss: 0.4984\n",
      "Epoch 152/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7997 - loss: 0.5162\n",
      "Epoch 153/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7804 - loss: 0.5138\n",
      "Epoch 154/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7387 - loss: 0.5657\n",
      "Epoch 155/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7762 - loss: 0.5499\n",
      "Epoch 156/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7954 - loss: 0.5297\n",
      "Epoch 157/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7758 - loss: 0.5285\n",
      "Epoch 158/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7596 - loss: 0.5659\n",
      "Epoch 159/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7690 - loss: 0.5094\n",
      "Epoch 160/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7379 - loss: 0.5596\n",
      "Epoch 161/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8030 - loss: 0.4835\n",
      "Epoch 162/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7712 - loss: 0.5272\n",
      "Epoch 163/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7718 - loss: 0.5435\n",
      "Epoch 164/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7906 - loss: 0.5322\n",
      "Epoch 165/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7899 - loss: 0.5106\n",
      "Epoch 166/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7951 - loss: 0.5127\n",
      "Epoch 167/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7806 - loss: 0.5534\n",
      "Epoch 168/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7688 - loss: 0.5359\n",
      "Epoch 169/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7768 - loss: 0.5443\n",
      "Epoch 170/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7662 - loss: 0.5526\n",
      "Epoch 171/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7775 - loss: 0.5459\n",
      "Epoch 172/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7867 - loss: 0.5074\n",
      "Epoch 173/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7717 - loss: 0.5335\n",
      "Epoch 174/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7759 - loss: 0.5206\n",
      "Epoch 175/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7868 - loss: 0.5161\n",
      "Epoch 176/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7808 - loss: 0.5381\n",
      "Epoch 177/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8117 - loss: 0.4934\n",
      "Epoch 178/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7963 - loss: 0.5318\n",
      "Epoch 179/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7922 - loss: 0.5236\n",
      "Epoch 180/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7604 - loss: 0.5376\n",
      "Epoch 181/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7564 - loss: 0.5280\n",
      "Epoch 182/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7698 - loss: 0.5462\n",
      "Epoch 183/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7859 - loss: 0.5477\n",
      "Epoch 184/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7743 - loss: 0.5322\n",
      "Epoch 185/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7994 - loss: 0.5269\n",
      "Epoch 186/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7764 - loss: 0.5137\n",
      "Epoch 187/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7901 - loss: 0.5152\n",
      "Epoch 188/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8082 - loss: 0.5053\n",
      "Epoch 189/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7905 - loss: 0.5230\n",
      "Epoch 190/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7713 - loss: 0.5596\n",
      "Epoch 191/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7864 - loss: 0.5380\n",
      "Epoch 192/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7913 - loss: 0.5351\n",
      "Epoch 193/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7770 - loss: 0.5403\n",
      "Epoch 194/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7801 - loss: 0.5236\n",
      "Epoch 195/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8009 - loss: 0.5146\n",
      "Epoch 196/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7593 - loss: 0.5538\n",
      "Epoch 197/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7944 - loss: 0.5214\n",
      "Epoch 198/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7596 - loss: 0.5655\n",
      "Epoch 199/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7915 - loss: 0.5347\n",
      "Epoch 200/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7826 - loss: 0.5314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x245ec752990>"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on the training data\n",
    "model.fit(\n",
    "    X_train,             # Input features (X_train)\n",
    "    y_train,             # Target labels (y_train)\n",
    "    epochs=200,          # Number of training epochs (iterations over the entire dataset)\n",
    "    batch_size=4,        # Number of samples per gradient update\n",
    "    verbose=1            # Verbosity mode (1: progress bar, 0: silent)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.8889 - loss: 0.5282\n",
      "Test Accuracy: 0.8888888955116272\n",
      "Test Loss: 0.528242290019989\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's performance on the cross-validation dataset\n",
    "loss, accuracy = model.evaluate(X_cv, y_cv, verbose=1)\n",
    "\n",
    "# Print the test accuracy and test loss\n",
    "print(f\"Test Accuracy: {accuracy}\")  # Print the accuracy achieved by the model on the cross-validation set\n",
    "print(f\"Test Loss: {loss}\")           # Print the loss value obtained by the model on the cross-validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(418,)"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict probabilities of survival for the test set using the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predicted probabilities to binary predictions based on a threshold of 0.8\n",
    "# If the predicted probability is greater than 0.8, classify as survived (1), otherwise classify as not survived (0)\n",
    "y_pred = (y_pred > 0.8).astype(int).ravel()\n",
    "\n",
    "# Shape of the predicted labels array\n",
    "y_pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         0\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         0\n",
      "5            897         0\n",
      "6            898         0\n",
      "7            899         0\n",
      "8            900         0\n",
      "9            901         0\n",
      "10           902         0\n",
      "11           903         0\n",
      "12           904         1\n",
      "13           905         0\n",
      "14           906         1\n",
      "15           907         0\n",
      "16           908         0\n",
      "17           909         0\n",
      "18           910         0\n",
      "19           911         0\n",
      "20           912         0\n",
      "21           913         0\n",
      "22           914         0\n",
      "23           915         0\n",
      "24           916         1\n",
      "25           917         0\n",
      "26           918         1\n",
      "27           919         0\n",
      "28           920         0\n",
      "29           921         0\n",
      "30           922         0\n",
      "31           923         0\n",
      "32           924         0\n",
      "33           925         0\n",
      "34           926         0\n",
      "35           927         0\n",
      "36           928         0\n",
      "37           929         0\n",
      "38           930         0\n",
      "39           931         0\n",
      "40           932         0\n",
      "41           933         0\n",
      "42           934         0\n",
      "43           935         0\n",
      "44           936         1\n",
      "45           937         0\n",
      "46           938         0\n",
      "47           939         0\n",
      "48           940         1\n",
      "49           941         0\n",
      "50           942         0\n",
      "51           943         0\n",
      "52           944         0\n",
      "53           945         0\n",
      "54           946         0\n",
      "55           947         0\n",
      "56           948         0\n",
      "57           949         0\n",
      "58           950         0\n",
      "59           951         1\n",
      "60           952         0\n",
      "61           953         0\n",
      "62           954         0\n",
      "63           955         0\n",
      "64           956         0\n",
      "65           957         0\n",
      "66           958         0\n",
      "67           959         0\n",
      "68           960         0\n",
      "69           961         1\n",
      "70           962         0\n",
      "71           963         0\n",
      "72           964         0\n",
      "73           965         0\n",
      "74           966         1\n",
      "75           967         0\n",
      "76           968         0\n",
      "77           969         0\n",
      "78           970         0\n",
      "79           971         0\n",
      "80           972         0\n",
      "81           973         0\n",
      "82           974         0\n",
      "83           975         0\n",
      "84           976         0\n",
      "85           977         0\n",
      "86           978         0\n",
      "87           979         0\n",
      "88           980         0\n",
      "89           981         0\n",
      "90           982         0\n",
      "91           983         0\n",
      "92           984         1\n",
      "93           985         0\n",
      "94           986         0\n",
      "95           987         0\n",
      "96           988         1\n",
      "97           989         0\n",
      "98           990         0\n",
      "99           991         0\n",
      "100          992         1\n",
      "101          993         0\n",
      "102          994         0\n",
      "103          995         0\n",
      "104          996         0\n",
      "105          997         0\n",
      "106          998         0\n",
      "107          999         0\n",
      "108         1000         0\n",
      "109         1001         0\n",
      "110         1002         0\n",
      "111         1003         0\n",
      "112         1004         1\n",
      "113         1005         0\n",
      "114         1006         1\n",
      "115         1007         0\n",
      "116         1008         0\n",
      "117         1009         0\n",
      "118         1010         0\n",
      "119         1011         0\n",
      "120         1012         0\n",
      "121         1013         0\n",
      "122         1014         1\n",
      "123         1015         0\n",
      "124         1016         0\n",
      "125         1017         0\n",
      "126         1018         0\n",
      "127         1019         0\n",
      "128         1020         0\n",
      "129         1021         0\n",
      "130         1022         0\n",
      "131         1023         0\n",
      "132         1024         0\n",
      "133         1025         0\n",
      "134         1026         0\n",
      "135         1027         0\n",
      "136         1028         0\n",
      "137         1029         0\n",
      "138         1030         0\n",
      "139         1031         0\n",
      "140         1032         0\n",
      "141         1033         0\n",
      "142         1034         0\n",
      "143         1035         0\n",
      "144         1036         0\n",
      "145         1037         0\n",
      "146         1038         0\n",
      "147         1039         0\n",
      "148         1040         0\n",
      "149         1041         0\n",
      "150         1042         1\n",
      "151         1043         0\n",
      "152         1044         0\n",
      "153         1045         0\n",
      "154         1046         0\n",
      "155         1047         0\n",
      "156         1048         0\n",
      "157         1049         0\n",
      "158         1050         0\n",
      "159         1051         0\n",
      "160         1052         0\n",
      "161         1053         0\n",
      "162         1054         0\n",
      "163         1055         0\n",
      "164         1056         0\n",
      "165         1057         0\n",
      "166         1058         0\n",
      "167         1059         0\n",
      "168         1060         1\n",
      "169         1061         0\n",
      "170         1062         0\n",
      "171         1063         0\n",
      "172         1064         0\n",
      "173         1065         0\n",
      "174         1066         0\n",
      "175         1067         0\n",
      "176         1068         0\n",
      "177         1069         0\n",
      "178         1070         0\n",
      "179         1071         1\n",
      "180         1072         0\n",
      "181         1073         0\n",
      "182         1074         1\n",
      "183         1075         0\n",
      "184         1076         1\n",
      "185         1077         0\n",
      "186         1078         0\n",
      "187         1079         0\n",
      "188         1080         0\n",
      "189         1081         0\n",
      "190         1082         0\n",
      "191         1083         0\n",
      "192         1084         0\n",
      "193         1085         0\n",
      "194         1086         0\n",
      "195         1087         0\n",
      "196         1088         0\n",
      "197         1089         0\n",
      "198         1090         0\n",
      "199         1091         0\n",
      "200         1092         0\n",
      "201         1093         0\n",
      "202         1094         0\n",
      "203         1095         0\n",
      "204         1096         0\n",
      "205         1097         0\n",
      "206         1098         0\n",
      "207         1099         0\n",
      "208         1100         1\n",
      "209         1101         0\n",
      "210         1102         0\n",
      "211         1103         0\n",
      "212         1104         0\n",
      "213         1105         0\n",
      "214         1106         0\n",
      "215         1107         0\n",
      "216         1108         0\n",
      "217         1109         0\n",
      "218         1110         1\n",
      "219         1111         0\n",
      "220         1112         0\n",
      "221         1113         0\n",
      "222         1114         0\n",
      "223         1115         0\n",
      "224         1116         1\n",
      "225         1117         0\n",
      "226         1118         0\n",
      "227         1119         0\n",
      "228         1120         0\n",
      "229         1121         0\n",
      "230         1122         0\n",
      "231         1123         0\n",
      "232         1124         0\n",
      "233         1125         0\n",
      "234         1126         0\n",
      "235         1127         0\n",
      "236         1128         0\n",
      "237         1129         0\n",
      "238         1130         0\n",
      "239         1131         1\n",
      "240         1132         1\n",
      "241         1133         0\n",
      "242         1134         0\n",
      "243         1135         0\n",
      "244         1136         0\n",
      "245         1137         0\n",
      "246         1138         0\n",
      "247         1139         0\n",
      "248         1140         0\n",
      "249         1141         0\n",
      "250         1142         0\n",
      "251         1143         0\n",
      "252         1144         0\n",
      "253         1145         0\n",
      "254         1146         0\n",
      "255         1147         0\n",
      "256         1148         0\n",
      "257         1149         0\n",
      "258         1150         0\n",
      "259         1151         0\n",
      "260         1152         0\n",
      "261         1153         0\n",
      "262         1154         0\n",
      "263         1155         0\n",
      "264         1156         0\n",
      "265         1157         0\n",
      "266         1158         0\n",
      "267         1159         0\n",
      "268         1160         0\n",
      "269         1161         0\n",
      "270         1162         0\n",
      "271         1163         0\n",
      "272         1164         1\n",
      "273         1165         0\n",
      "274         1166         0\n",
      "275         1167         0\n",
      "276         1168         0\n",
      "277         1169         0\n",
      "278         1170         0\n",
      "279         1171         0\n",
      "280         1172         0\n",
      "281         1173         0\n",
      "282         1174         0\n",
      "283         1175         0\n",
      "284         1176         0\n",
      "285         1177         0\n",
      "286         1178         0\n",
      "287         1179         0\n",
      "288         1180         0\n",
      "289         1181         0\n",
      "290         1182         0\n",
      "291         1183         0\n",
      "292         1184         0\n",
      "293         1185         0\n",
      "294         1186         0\n",
      "295         1187         0\n",
      "296         1188         0\n",
      "297         1189         0\n",
      "298         1190         0\n",
      "299         1191         0\n",
      "300         1192         0\n",
      "301         1193         0\n",
      "302         1194         0\n",
      "303         1195         0\n",
      "304         1196         0\n",
      "305         1197         1\n",
      "306         1198         0\n",
      "307         1199         0\n",
      "308         1200         0\n",
      "309         1201         0\n",
      "310         1202         0\n",
      "311         1203         0\n",
      "312         1204         0\n",
      "313         1205         0\n",
      "314         1206         1\n",
      "315         1207         0\n",
      "316         1208         0\n",
      "317         1209         0\n",
      "318         1210         0\n",
      "319         1211         0\n",
      "320         1212         0\n",
      "321         1213         0\n",
      "322         1214         0\n",
      "323         1215         0\n",
      "324         1216         0\n",
      "325         1217         0\n",
      "326         1218         0\n",
      "327         1219         0\n",
      "328         1220         0\n",
      "329         1221         0\n",
      "330         1222         0\n",
      "331         1223         0\n",
      "332         1224         0\n",
      "333         1225         0\n",
      "334         1226         0\n",
      "335         1227         0\n",
      "336         1228         0\n",
      "337         1229         0\n",
      "338         1230         0\n",
      "339         1231         0\n",
      "340         1232         0\n",
      "341         1233         0\n",
      "342         1234         1\n",
      "343         1235         1\n",
      "344         1236         0\n",
      "345         1237         0\n",
      "346         1238         0\n",
      "347         1239         0\n",
      "348         1240         0\n",
      "349         1241         0\n",
      "350         1242         1\n",
      "351         1243         0\n",
      "352         1244         0\n",
      "353         1245         0\n",
      "354         1246         0\n",
      "355         1247         0\n",
      "356         1248         1\n",
      "357         1249         0\n",
      "358         1250         0\n",
      "359         1251         0\n",
      "360         1252         0\n",
      "361         1253         0\n",
      "362         1254         0\n",
      "363         1255         0\n",
      "364         1256         1\n",
      "365         1257         1\n",
      "366         1258         0\n",
      "367         1259         0\n",
      "368         1260         1\n",
      "369         1261         0\n",
      "370         1262         0\n",
      "371         1263         1\n",
      "372         1264         0\n",
      "373         1265         0\n",
      "374         1266         1\n",
      "375         1267         1\n",
      "376         1268         0\n",
      "377         1269         0\n",
      "378         1270         0\n",
      "379         1271         0\n",
      "380         1272         0\n",
      "381         1273         0\n",
      "382         1274         0\n",
      "383         1275         0\n",
      "384         1276         0\n",
      "385         1277         0\n",
      "386         1278         0\n",
      "387         1279         0\n",
      "388         1280         0\n",
      "389         1281         0\n",
      "390         1282         0\n",
      "391         1283         0\n",
      "392         1284         0\n",
      "393         1285         0\n",
      "394         1286         0\n",
      "395         1287         1\n",
      "396         1288         0\n",
      "397         1289         1\n",
      "398         1290         0\n",
      "399         1291         0\n",
      "400         1292         0\n",
      "401         1293         0\n",
      "402         1294         1\n",
      "403         1295         0\n",
      "404         1296         0\n",
      "405         1297         0\n",
      "406         1298         0\n",
      "407         1299         0\n",
      "408         1300         0\n",
      "409         1301         0\n",
      "410         1302         0\n",
      "411         1303         1\n",
      "412         1304         0\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         0\n"
     ]
    }
   ],
   "source": [
    "passenger_ids = test_set['PassengerId']\n",
    "y_pred_df= pd.DataFrame(y_pred, columns=['survived'])\n",
    "y_pred = y_pred_df['survived']\n",
    "result = pd.DataFrame({'PassengerId':passenger_ids, 'Survived':y_pred})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8866 - loss: 0.4296\n",
      "Test Accuracy: 0.8899521827697754\n",
      "Test Loss: 0.4306966960430145\n"
     ]
    }
   ],
   "source": [
    "# Extract ground truth labels for the test set\n",
    "y_test = Y_test['Survived']\n",
    "\n",
    "# Evaluate the model's performance on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Print the test loss\n",
    "print(f\"Test Loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves the DataFrame result to a CSV file named 'Y_pred.csv'\n",
    "result.to_csv(r'C:\\Users\\Hp\\OneDrive\\Desktop\\Kaggle work\\titanic\\Y_pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
