{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import MeanSquaredError,BinaryCrossentropy\n",
    "from tensorflow.keras.activations import sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# ignores (suppresses) all warnings raised during the execution of your Python code.\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_train_set = pd.read_csv(r'C:\\Users\\Hp\\OneDrive\\Desktop\\Kaggle work\\titanic\\train.csv')\n",
    "test_set = pd.read_csv(r'C:\\Users\\Hp\\OneDrive\\Desktop\\Kaggle work\\titanic\\test.csv')\n",
    "Y_test = pd.read_csv(r'C:\\Users\\Hp\\OneDrive\\Desktop\\Kaggle work\\titanic\\gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ini_train_set.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "ini_train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ini_train_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training data shape\n",
    "ini_train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test data shape\n",
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop cabin and ticket from the training data set\n",
    "ini_train_set.drop(['Cabin','Ticket'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop cabin and ticket from the test data set\n",
    "test_set.drop(['Cabin', 'Ticket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.472826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.242363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Survived\n",
       "0       1  0.629630\n",
       "1       2  0.472826\n",
       "2       3  0.242363"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#groups the DataFrame ini_train_set by the 'Pclass' column and then calculates the mean of the 'Survived' column for each group. \n",
    "ini_train_set.groupby(['Pclass'], as_index=False)['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Survived\n",
       "0  female  0.742038\n",
       "1    male  0.188908"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#groups the DataFrame ini_train_set by the 'Sex' column and then calculates the mean of the 'Survived' column for each group. \n",
    "ini_train_set.groupby(['Sex'], as_index=False)['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.345395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.535885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.464286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SibSp  Survived\n",
       "0      0  0.345395\n",
       "1      1  0.535885\n",
       "2      2  0.464286\n",
       "3      3  0.250000\n",
       "4      4  0.166667\n",
       "5      5  0.000000\n",
       "6      8  0.000000"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#groups the DataFrame ini_train_set by the 'SibSp' column and then calculates the mean of the 'Survived' column for each group. \n",
    "ini_train_set.groupby(['SibSp'], as_index=False)['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parch</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.343658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.550847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parch  Survived\n",
       "0      0  0.343658\n",
       "1      1  0.550847\n",
       "2      2  0.500000\n",
       "3      3  0.600000\n",
       "4      4  0.000000\n",
       "5      5  0.200000\n",
       "6      6  0.000000"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#groups the DataFrame ini_train_set by the 'Parch' column and then calculates the mean of the 'Survived' column for each group. \n",
    "ini_train_set.groupby(['Parch'], as_index=False)['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>0.553571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q</td>\n",
       "      <td>0.389610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>0.336957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Embarked  Survived\n",
       "0        C  0.553571\n",
       "1        Q  0.389610\n",
       "2        S  0.336957"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#groups the DataFrame ini_train_set by the 'Embarked' column and then calculates the mean of the 'Survived' column for each group. \n",
    "ini_train_set.groupby(['Embarked'], as_index=False)['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Age histogram grouped by Survive \n",
    "# Set the style of the visualization\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Create a histogram of the 'Age' variable split by 'Survived'\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(data=ini_train_set, x='Age', hue='Survived', bins=200, alpha=0.6)\n",
    "plt.title('Histogram of Age by Survived')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Survived', labels=['Yes', 'No'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArQAAAGHCAYAAABBOMFEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABIdElEQVR4nO3deXhMd///8ddklSBCRGppqSK1RMQS3Ha17w333W+1lGpRUb21td9FK0rR2pe6UW21qPW2tKjepailokKrlFgae1K7LJPl/P7wM3fHJCQkmRyej+uaq+ZzzpzznnmP9OXkc86xGIZhCAAAADApF2cXAAAAADwIAi0AAABMjUALAAAAUyPQAgAAwNQItAAAADA1Ai0AAABMjUALAAAAUyPQAgAAwNQItAByHfdzAQBkJwItADtDhw5V06ZNM1zetGlTDR06NMPn9/Ldd99pyJAhD1Tjw+DIkSPq1KmTqlSpojZt2qS7zvTp0xUYGJjhY/78+blc9f9kte9ZcfnyZY0bN07NmjVTlSpVFBoaqpdeeknffvttjuwvPbt371ZgYKB2796d4/tauXKlAgMDdfr06RzfF/CwcnN2AQDMbcaMGSpQoECm11+4cGHOFWMiM2fO1NmzZzVz5kwVKVLkrusuXbo03fESJUrkRGlOlZiYqBdeeEGpqanq3bu3SpcurevXr+ubb75R//79NXz4cL300ks5XkflypW1dOlSlStXLsf3BeDBEWgBPJBKlSo5uwRTunz5sipUqKBGjRrdc91q1arlfEF5xIYNGxQdHa2NGzeqTJkytvFmzZopMTFR06ZN04svvihXV9ccraNAgQKP1OcOmB1TDgA8kDt/9bxu3Tp16NBBVatWVZ06dfT222/rwoULkqRu3bppz5492rNnj92vcy9evKhhw4apUaNGqlq1qrp06aLvvvvObj83btzQyJEjVbduXYWEhGjgwIFauHChAgMDbet069ZNb7/9tgYMGKBq1aqpZ8+ekqTTp09r8ODBql+/vipXrqy6detq8ODBunz5st37mDFjht5//33Vrl1bISEheuutt3Tz5k3NnTtXDRs2VI0aNfT666/bvS4993o/gYGB2rNnj3766ScFBgZq5cqV9/np/8+yZcsUFhamatWqqWrVqurYsaO++eYb2/KVK1eqUqVKWrZsmerVq6fQ0FAdO3ZMkrR582aFhYUpKChI9erVU0REhOLj4++5z+TkZEVERKhWrVqqWbOmhgwZokuXLkmStmzZosDAQG3fvt3uNXv37lVgYKAiIyPT3WZcXJwkKS0tzWFZnz591K9fP1mtVknpT485ffq03Wd6e+rAkiVL1KRJE1WvXl2rVq1SYGCgfv/9d7vXbt68WYGBgTp06JDdlIN9+/YpMDBQ33//vd36v/32mwIDA21TIZKSkjRhwgQ1atRIVapUUfv27fX111/bvSYtLU2zZs1S48aNFRwcrH79+unq1asZf8gAMoVACyBdKSkp6T7uJjIyUoMHD1aLFi3073//W8OGDdOuXbv01ltvSZJGjRqlSpUqqVKlSlq6dKkqV66suLg4denSRXv37tXAgQM1ffp0lSxZUuHh4VqzZo1t2/369dM333yj119/XZMnT9bNmzf14YcfOtTwzTffKH/+/Jo9e7ZeeeUVJSQkqHv37oqOjtaoUaM0f/58de/eXevXr9fkyZPtXrtgwQKdO3dOkydP1muvvaZ169apc+fO2r59u8aMGaM333xT3333naZNm5bhZ5CZ97N06VK7z6Fx48ZZ7sVfA98XX3yhkSNHqlmzZvr44481adIkeXh46O2339b58+dt66WmpmrBggUaO3ashg0bpqeeekpr165VeHi4ypYtq5kzZ6p///5as2aN+vXrd8+T97755hv9+uuvGj9+vIYMGaItW7bo1VdfVWpqqho0aKBixYrpP//5j91rVq9erTJlyqhGjRrpbrNBgwZyc3PTSy+9pBkzZmj//v1KTk6WJFWtWlW9evWSl5fXXetKz4wZMzRkyBCNHDlSLVu2lLe3t9avX2+3zrp161S+fHmH3zpUr15dTzzxRLrr+/r6qlGjRjIMQ+Hh4VqyZIl69uyp2bNn2/7htXr1attrJk6cqJkzZ6pLly6aMWOGfH190/0eA8gaphwAcHDmzBlVrlw5y6+LjIxUvnz51Lt3b3l4eEiSfH19dfDgQRmGoXLlytnm297+de7s2bN16dIlbdy4USVLlpQkNWrUSD169NCECRPUrl077d69W7t379b06dPVokULSVLDhg3Vrl07RUdH29Xg7u6ud99917b/3377TY899pg++OADPf7445KkOnXqKCoqSnv27LF7bYECBTR58mS5ubnpb3/7m1atWqULFy5o2bJlKliwoCRp27Zt2rdvX4afwSeffHLP91OtWjWHz+Fu0uvFc889p/fee0+SFBMTo169eqlfv3625SVLllRYWJgiIyPVtm1b23jfvn1tAdowDE2aNEkNGjTQpEmTbOuUKVNGPXr00NatW+8atgsXLqz58+fL29vb9jw8PFw//PCDmjRpomeffVaff/65bt68qfz58ysxMVHffPONevfuneE2AwMDNXnyZL377ruaPn26pk+frnz58qlmzZrq0qWLWrdufc/PKz1du3ZVq1atbM9btmypr7/+WgMHDpQk3bx5U99//73Cw8PTfX2HDh20YMECJSYmKl++fDIMQ19//bVatWolDw8P7dixQ9u2bdPkyZNtJ/k1aNBACQkJmjRpktq1a6f4+Hh9/vnn6tmzp/r3729b5+LFi9q2bdt9vS8AtxBoATjw9/fX7Nmz01322muvZfi6WrVqafLkyWrXrp1atmypRo0aqX79+nedJ7pnzx6FhITYwt9tHTp00LBhw3T8+HHt2rVL7u7uatasmW25i4uL2rRpo+nTp9u9rmzZsrYwK0kVK1bUl19+qbS0NJ08eVKnTp3SsWPHdPz4cYcjzlWrVpWb2/9+LBYtWlTe3t62MCvdCuh3/qo6q+8nqycaLV++3GHMz8/P9ufbUz6uXbum48eP69SpU7bpHLd/PX9bxYoVbX8+fvy4zp8/rz59+th9FrVq1VKBAgW0Y8eOuwbaRo0a2cKsdGvahpubm3766Sc1adJEnTt31scff6xvv/1WnTp10rfffqv4+Hh16tTpru+3RYsWatKkiXbt2qUff/xRu3fv1o8//qjt27frm2++0dSpU2WxWO66jTv99X1LUseOHbVq1SodOHBAVatW1XfffSer1aoOHTqk+/oOHTpoxowZ+v7779W6dWvt27dPZ8+eVceOHSVJO3fulMViUaNGjew+y6ZNm2rNmjU6evSoYmNjlZycrCZNmthtu3Xr1gRa4AERaAE48PDwUFBQUIbLMhISEqK5c+dq4cKF+uSTTzR37lwVLVpUffv2Vbdu3dJ9zdWrV21HTv+qaNGikm6FtMuXL8vX11cuLvazpP4a6m7Lnz+/w9gnn3yiOXPm6MqVKypatKiqVKkiLy8vXb9+3W699K7W8NfAlhmZeT9ZlVEvbvvjjz80cuRI7dy5U+7u7ipbtqyefvppSY7X/P3r+7ly5Yok6d1339W7777rsN2LFy/edb/+/v52z11cXFS4cGHbeyxdurRCQ0O1evVqderUSatXr9bf/vY3BQQE3HW70q0j7Q0aNFCDBg0kSRcuXFBERIQ2btyoLVu2OITCe7mzj7Vr11ZAQIDWr1+vqlWrav369QoNDdVjjz2W7utLly6tkJAQrV+/Xq1bt9b69ev1xBNPqHr16pJufZaGYdie3+nixYu2z6Vw4cJ2y+78HAFkHYEWQLa6HUISEhK0a9cuffbZZ4qIiFBwcLCqVq3qsH6hQoUUGxvrMH57rHDhwgoICNDly5eVlpZmF2r//PPPe9azdu1ajR8/XoMGDVJYWJjtEllvvPGGDh48eL9vM0OZeT/ZKS0tTb1795a7u7uWL1+uihUrys3NTceOHXOYv3onHx8fSdLgwYMVGhrqsLxQoUJ3ff3tQHxbamqqLl++bPcPjc6dO2v48OGKjo7Wzp077aY2pOf//u//9OSTT2rcuHF24wEBARo7dqw2bdqkY8eOqUmTJrJYLEpNTbVbLzMns0m3wnf79u21bt069e3bVzt27LBN4chIhw4dNG7cOF2/fl0bNmzQ888/b1tWsGBBeXt767PPPkv3taVLl9aBAwck3freli1b1rbszs8RQNZxUhiAbPPBBx+oc+fOMgxDXl5eatKkie0mCmfPnpUkh6OstWrV0s8//6wzZ87Yja9Zs0b+/v62o3wpKSn673//a1tuGIY2b958z5oiIyPl4+OjV155xRZmb968qcjIyHTPpH9QmXk/2eny5cs6ceKEunTpoqCgINuUiR9++EFS+lcLuK1s2bLy8/PT6dOnFRQUZHsEBAToww8/1KFDh+667x07dtj9en3jxo1KSUlR7dq1bWMtW7aUl5eXRo8erfz589tNG0lPyZIltWHDBsXExDgsO3HihCSpQoUKkm4djb98+bKSkpJs62R09YT0dOzYUefPn9fMmTPl6upqm5+dkTZt2sgwDE2dOlV//vmn3fSE0NBQxcfHyzAMu8/y999/18yZM5WSkqKQkBDly5dPGzZssNvunVdPAJB1HKEFkG3q1KmjTz75REOHDlWHDh2UnJysefPmydfXV3Xq1JF066jgzz//rJ07d6pSpUrq2bOn1qxZox49eqh///7y9fXV6tWrtWvXLr3//vtycXFRrVq1VK9ePY0YMUJxcXEqUaKEli9friNHjtxzLmXVqlW1ePFijR8/Xk2aNNHFixc1f/58xcXF3fMI5P3IzPvJTn5+fipZsqS++OILPfbYY/Lx8dG2bdtsRwoTEhIyfK2rq6sGDhyokSNHytXVVU2aNNG1a9c0a9YsXbhw4Z4nBsbGxur1119Xt27ddPLkSX300UeqV6+e6tata1vHy8tLbdu21dKlS/X888/fdcqKJA0cOFC7d+9Wly5d1L17d4WEhMjFxUUHDx7UggUL1LBhQzVs2FCS1KRJE33++ecaMWKEunTpot9//12ffPJJpq9RW6FCBdsc69atW9/zBiG3r2jw5ZdfKiQkxO4fJ40aNVKtWrXUr18/9evXT0899ZQOHDigadOmqUGDBrZ/TPXr109TpkyRl5eX6tSpo61btxJogWzAEVoA2aZRo0aaNGmSjh49qv79++vNN9+Ul5eXPvvsM/n6+kqSXnjhBbm7u+vVV1/VDz/8IH9/fy1evFiVK1dWRESE3njjDZ07d06zZs1S586dbduePHmymjZtqg8//FBvvPGGPDw89Pzzz99zjuuzzz6r8PBwffPNN3r11Vc1bdo01axZU++9956uXLnicJWEB5XZ95OdZs2apYCAAA0dOlT//Oc/FRUVpdmzZ6ts2bLau3fvXV/797//XR9++KH27dunvn37avTo0SpVqpQ+//zzdOcC/1XXrl3l5+en8PBwTZ06Ve3bt9eMGTMc/pFx+8SysLCwe76XUqVKadWqVWrfvr3Wrl2rfv36qU+fPlq7dq169eqlmTNn2rZfr149DRkyRJGRkXr11Vf19ddfa8aMGVm66ULHjh2Vmpqa4clgGa3fvn17u3EXFxfNnTtXbdu21ccff6xevXrZLuH118vD9enTR8OHD9eGDRv02muv6ciRI9wKGsgGFuNeFxoEACc7c+aM9u/fr2eeeUb58uWzjQ8YMEAxMTFatWqVE6vDvYwaNUpRUVF212MFgOzElAMAeZ6Li4uGDh2qZ555Rl26dJGrq6u2bdumTZs2OZw8hLzjs88+0/Hjx/XVV19p4sSJzi4HwEOMI7QATGHXrl2aOXOmfvvtN6WkpOipp55Sz5491a5dO2eXhgwMGDBA27Zt03PPPWd3e2QAyG4EWgAAAJgaJ4UBAADA1Ai0AAAAMDUCLQAAAEztkb3KQVpamlJSUuTi4nLPC7MDAAAg9xmGobS0NLm5ud31xjSPbKBNSUnJkfu4AwAAIHsFBQXd9U6Dj2ygvZ3yg4KCsnRXmfuVmpqqgwcP5tr+kD3omznRN3Oib+ZE38zJLH27Xee9bhv+yAba29MMXF1dc7WRub0/ZA/6Zk70zZzomznRN3MyS9/uNT2Uk8IAAABgagRaAAAAmBqBFgAAAKb2yM6hBQAAyC2GYSglJUWpqanOLkWSbHUkJiY6dQ6tq6ur3NzcHvgSqgRaAACAHGS1WnXu3DnFx8c7uxQbwzDk5uamU6dOOf16/N7e3ipevPhdL8t1LwRaAACAHJKWlqYTJ07I1dVVJUqUkIeHh9MDpHQr0CYkJMjLy8tp9RiGIavVqtjYWJ04cULly5e/5+W5MkKgBQAAyCFWq1VpaWl6/PHH5e3t7exybG7fgStfvnxODdheXl5yd3fXqVOnZLValS9fvvvaDieFAQAA5LD7PfL4KMiOz4ZPFwAAAKZGoAUAAICpEWgBAADyiOTkZE2fPl3PPPOMqlSposaNG2vcuHG6ceNGtu9rzpw56tatW7ZvV5ICAwO1e/fuHNl2epwaaC9cuKABAwYoNDRUDRo00Lhx45SUlCRJioiIUGBgoN1j0aJFtteuW7dOzZo1U3BwsMLDw3Xp0iVnvY0Hcjneqj/+vOnwuBxvdXZpAAAgl02aNEmbNm1SRESENmzYoHHjxmnHjh16++23s31f3bt31/Tp07N9u87gtKscGIahAQMGyMfHR1988YWuXr2q4cOHy8XFRUOGDFF0dLTeeustPfvss7bXFChQQJJ04MABjRgxQu+++66efvppjR07VsOGDdPHH3/srLdz364nJGv21uMO4681KqvC3vd/PTYAAGA+q1at0vvvv6+6detKkkqVKqXRo0frhRde0MWLF1WsWLFs25e3t3eeuvLCg3DaEdrjx49r//79GjdunMqXL6+aNWtqwIABWrdunSQpOjpalSpVkr+/v+3h5eUlSVq0aJFat26tTp066emnn9aECRO0detWxcTEOOvtAAAAPDCLxaJdu3YpLS3NNhYSEqL169ercOHCatq0qVauXGlbtnv3bgUGBkqSTp8+rcDAQM2cOVO1atXSsGHDFBQUpF27dtnWv3HjhoKCghQZGWmbcpCWlqYGDRpoxYoVtvUMw1DDhg31n//8R5K0d+9ehYWFqWrVqmrfvr02btxoV/eMGTNUt25d1a5dW8uWLcuRz+ZunBZo/f39NW/ePBUtWtRu/MaNG7px44YuXLigMmXKpPvaqKgo1axZ0/a8ePHiKlGihKKionKyZAAAgBzVvXt3ff7552ratKlGjRqljRs3KjExUeXKlZO7u3umtrFv3z6tWLFCffr0UYMGDfTtt9/alm3ZskVFihRR9erVbWMuLi5q1aqV3Xr79+/XlStX9Mwzzyg2NlZ9+vRRWFiY1q5dq1deeUVDhw7V3r17JUlLly7VZ599pvfff18LFy60C8a5xWlTDnx8fNSgQQPb87S0NC1atEh16tRRdHS0LBaL5syZox9++EG+vr7q2bOnbfpBeofc/fz8dP78+SzXkVv3VL69nzv3ZxiSYaQ5rG8YuVcbMpZR35C30Tdzom/mRN/uLjU1VYZh2B730q9fPz3++OP68ssv9dVXX2nJkiXKnz+/hg8frs6dOzts66//vf3nl156SY8//rgkqU2bNpowYYJGjBghi8WiDRs2qFWrVnb7NAxDbdq0Uffu3XX9+nUVKFBAGzZsUMOGDZU/f37NmzdPdevW1QsvvCBJeuKJJ3To0CEtXLhQNWrU0FdffaWXXnpJjRs3liSNGTNG7dq1y/R7vr1eamqqw/cos9+rPHOnsIkTJ+rQoUNavny5fv31V1ksFpUtW1YvvviifvrpJ73zzjsqUKCAmjdvrsTERIf7/Xp4eMhqzfqJVAcPHsyut3Bf+3MvXFx//vmnw3pXr/kr7tTh3CoL95Db3xNkD/pmTvTNnOhbxtzc3JSQkGA3jeBunnnmGT3zzDO6cuWKdu7cqSVLluhf//qXSpcubbtdbHx8vCTZTqaPj49XYmKiJKlIkSK25XXq1NHVq1e1e/dulS9fXtu2bdO///1vJSQkSLp1QDE+Pl4VKlRQ0aJF9e2336ply5batGmT3njjDcXHx+v333/X1q1bFRISYqsxJSVFpUuXVnx8vI4dO6ZevXrZ9lmiRAl5eXkpKSnJNnY3SUlJSk5O1uHD95978kSgnThxoj799FNNnjxZFSpUUPny5dWkSRP5+vpKkp5++mmdPHlSixcvVvPmzeXp6ekQXq1Wq22ObVYEBQXJ1dU1O97GXaWmpurgwYMO+zt9OVF+fn4O6xfyKaRSpQNyvC7cXUZ9Q95G38yJvpkTfbu7xMREnTp1Sl5eXve8reuRI0e0atUqDR06VNKtk7Y6d+6s9u3bq2XLloqKipKLi4s8PDxsJ3O5ubnZ1r29/UKFCtmWe3t7q2nTpvrhhx909epV+fv7q1atWrYjpy4uLrZ127Ztqy1btqh8+fK6cuWKWrRoYctWHTp0UJ8+fezqdXNzk7e3tywWizw9Pe1OMHN3d3cYy4iLi4vc3d1Vrlw5h8/o9vfrXpweaMeMGaPFixdr4sSJatmypaRbE6Jvh9nbypYta5vUHBAQoLi4OLvlcXFx8vf3z/L+XV1dc/Uv4J37s1gki8VxKrPFIn4w5CG5/T1B9qBv5kTfzIm+pc/V1VUWi8X2uJvU1FQtXLhQHTt2VKVKlWzjnp6eypcvn4oUKSJ3d3fFx8fbtnX69GlJstv+nftq27atPvroI8XFxalNmzYOddx+3rZtW7344osqXbq0mjZtagujTz75pH7++We7c5sWLFggq9Wqvn37qnz58jp48KCeeeYZW03Xrl3L1Hv+a70P8h1y6nVoZ8yYoSVLluijjz5S27ZtbeNTp05Vjx497NY9fPiwypYtK0kKDg5WZGSkbdm5c+d07tw5BQcH50rdAAAA2a1y5cpq3Lix+vXrp7Vr1+r06dPav3+/Ro0aJavVqhYtWigoKEjLly/X77//rt27d2vBggX33G7Dhg118eJFbd68WW3atMlwvYoVK6pYsWK2q0nd1rVrV/3yyy+aPHmyTp48qbVr1+qjjz5SiRIlJEkvvviiPvvsM23cuFG///67RowYIReX3I2YTgu00dHRmjVrll599VXVqFFDsbGxtkeTJk30008/af78+frjjz/05ZdfavXq1Xr55ZclSc8//7z+85//aNmyZTp8+LAGDx6sxo0b2yZAAwAAmNGUKVPUsWNHzZgxQ61bt1afPn1048YNLVq0SAUKFNA///lP+fj4KCwsTGPHjtUbb7xxz216eHioWbNmeuyxx/T000/fdd02bdrI1dVVDRs2tI2VLFlSc+bM0bZt29SuXTtNmTJFQ4cOVYcOHSRJHTt21IABAzRmzBh17dpV9erVk4+Pz4N9EFlkMTJz+lkOmDt3rj788MN0lx05ckSbN2/WtGnTdPLkSZUsWVIDBw5UixYtbOusXLlS06ZN09WrV1WvXj2NGTNGhQsXzvT+U1NTtX//flWrVi3X5tCmt78//ryZ4Y0VnvDLn+N14e5y+3uC7EHfzIm+mRN9u7vExESdOHFCTz755D3n0OYmwzAUHx9vmwPrTHf7jDL7/XLaHNrevXurd+/eGS5v1qyZmjVrluHysLAwhYWF5URpAAAAMBGnzqEFAAAAHhSBFgAAAKZGoAUAAICpEWgBAABgagRaAAAAmBqBFgAAAKZGoAUAAICpEWgBAABgak67sQIAAMAjLf6SlHgtd/aVz0fyLpKpVd98801FRkZqw4YN8vLyslvWs2dPJSQkaPHixU6/w9hfEWgBAACcIfGatGNy7uyr3sBMB9ohQ4aodevWmjNnjgYOHGgb37Rpk3766SetXLkyT4VZiSkHAAAA+IuAgAC9/vrr+uSTTxQTEyNJSkxM1Pjx49WzZ09VqFDByRU6ItACAADATrdu3VS6dGlNnDhRkjRv3jy5uLgoPDxc586dU9++fRUcHKymTZtqxowZSk1NlSQlJyfrX//6l2rXrq2QkBD17dtXFy5cyPF6CbQAAACw4+bmppEjR2rTpk3avHmz5s+fr1GjRsnT01P9+/eXn5+fVq1apXHjxmnt2rWaM2eOJOmLL77QTz/9pAULFmj58uW6efOm3n///ZyvN8f3AAAAANOpVauW2rdvrzfeeEMtW7ZUgwYNtHPnTp09e1bLli2Ti4uLypYtqyFDhmjYsGEKDw/X6dOn5enpqZIlS8rX11fjx4/XlStXcrxWAi0AAADS1bdvX61Zs0bh4eGSpOjoaF25ckU1atSwrZOWlqbExERdvnxZzz33nNavX6/69esrNDRUzZo1U1hYWI7XSaAFAABAujw9Pe3+m5KSorJly2rWrFkO6xYsWFCFCxfWf//7X23ZskVbtmzRRx99pHXr1umLL77I0SsjEGgBAACQKU8++aTOnj2rIkWKqGDBgpKkHTt2aOXKlZowYYJWr14tDw8PtWnTRq1bt9b+/fv13HPP6c8//1TRokVzrC5OCgMAAECm1K9fXyVLltSgQYN05MgR7d27V++88468vLzk6uqq69eva+zYsdq5c6diYmK0du1aPfbYYypcuHCO1sURWgAAAGfI53Prhge5ta9s4OrqqtmzZ2vMmDH6xz/+IW9vb7Vq1UpDhgyRJL3wwgs6f/68Bg0apKtXr6pKlSqaPXu2XF1ds2X/GSHQAgAAOIN3kUzfvctZSpUqpSNHjtiNPf7445o7d26667u4uGjQoEEaNGhQbpT3v/3m6t4AAACAbEagBQAAgKkRaAEAAGBqBFoAAACYGoEWAAAApkagBQAAgKkRaAEAAGBqBFoAAACYGoEWAAAApsadwgAAAJzgcrxV1xOSc2VfBb3cVdjbI9PrBwYGql27dvrwww/txleuXKkZM2bov//9b3aX+EAItAAAAE5wPSFZs7cez5V9vdaobJYCrSStW7dOXbp0Ud26dXOoquzDlAMAAAA4KFmypN577z1ZrVZnl3JPBFoAAAA4+Oc//6kLFy5o/vz5Ga5z/vx5vfHGGwoNDVXt2rUVERHhlABMoAUAAICDgIAADRgwQHPmzFFMTIzDcqvVqpdeekkJCQn6/PPPNWXKFG3ZskUTJkzI9VoJtAAAAEhXt27dVLp0aY0dO9Zh2bZt23ThwgVNnDhRgYGBqlu3rkaOHKnFixfr5s2buVongRYAAADpcnV11ejRo7VlyxZt3rzZbll0dLTKlCmjQoUK2caqV6+ulJQU/fHHH7laJ4EWAAAAGapevbo6d+6ssWPHKiEhwTbu6enpsG5qaqrdf3MLgRYAAAB39fbbbys+Pt7uBLEnn3xSJ0+e1JUrV2xj+/fvl5ubm5544olcrY9ACwAAgLsqXLiw3n77bZ05c8Y2Vq9ePT3++OMaPHiwjhw5ol27dmnMmDFq166dfHx8crU+bqwAAADgBAW93PVao7K5tq8H1aVLF61YsUIXL16UdGt+7axZszRmzBj94x//UP78+dW+fXu9+eabD7yvrCLQAgAAOEFhb48s370rtxw5csRhzGKxaMmSJXZjjz/+uObOnZtbZWWIKQcAAAAwNQItAAAATI1ACwAAAFMj0AIAAMDUCLQAAAA5zDAMZ5eQZ2XHZ+PUQHvhwgUNGDBAoaGhatCggcaNG6ekpCRJUkxMjHr06KFq1aqpTZs22r59u91rf/zxR7Vr107BwcHq3r27YmJinPEWAAAAMuTufutyWfHx8U6uJO+6/dnc/qzuh9Mu22UYhgYMGCAfHx998cUXunr1qoYPHy4XFxcNHjxY4eHhqlChglasWKHNmzerf//++vrrr1WiRAmdPXtW4eHhev3119WgQQPNnDlT/fr105o1a2SxWJz1lgAAAOy4urrK19fXdu1Wb2/vPJFVDMNQUlKSXFxcnFaPYRiKj4/XxYsX5evrK1dX1/veltMC7fHjx7V//37t2LFDRYsWlSQNGDBAH3zwgRo2bKiYmBgtWbJE3t7eeuqpp7Rz506tWLFCr7/+upYtW6YqVaro5ZdfliSNGzdO9erV0549e1S7dm1nvSUAAAAHjz32mCTZQm1eYBiGkpOT5e7u7vSA7evra/uM7pfTAq2/v7/mzZtnC7O33bhxQ1FRUapUqZK8vb1t4zVq1ND+/fslSVFRUapZs6ZtmZeXlypXrqz9+/cTaAEAQJ5isVhUvHhxFStWTMnJyc4uR5KUmpqqw4cPq1y5cg90ZPRBubu7Z8v+nRZofXx81KBBA9vztLQ0LVq0SHXq1FFsbKyKFStmt76fn5/Onz8vSfdcnhWpqan3UX3W3d7PnfszDMkw0hzWN4zcqw0Zy6hvyNvomznRN3Oib1nzIPNEs5OLy63TqLIrUD6Iu313Mvu9yjO3vp04caIOHTqk5cuXa+HChfLwsL8VnIeHh6xWqyQpISHhrsuz4uDBg/df9H24c3/uhYvrzz//dFjv6jV/xZ06nFtl4R5y+3uC7EHfzIm+mRN9M6eHpW95ItBOnDhRn376qSZPnqwKFSrI09NTV65csVvHarUqX758kiRPT0+H8Gq1WuXj45PlfQcFBeXKv0xSU1N18OBBh/2dvpwoPz8/h/UL+RRSqdIBOV4X7i6jviFvo2/mRN/Mib6Zk1n6drvOe3F6oB0zZowWL16siRMnqmXLlpKkgIAAHTt2zG69uLg42zSDgIAAxcXFOSyvWLFilvfv6uqaq428c38Wi2SxOF49zWJRnv6CPWpy+3uC7EHfzIm+mRN9M6eHpW9OvQ7tjBkztGTJEn300Udq27atbTw4OFi//vqrEhMTbWORkZEKDg62LY+MjLQtS0hI0KFDh2zLAQAA8OhwWqCNjo7WrFmz9Oqrr6pGjRqKjY21PUJDQ1W8eHENGzZMR48e1dy5c3XgwAF16dJFktS5c2ft27dPc+fO1dGjRzVs2DCVKlWKKxwAAAA8gpwWaL/77julpqZq9uzZql+/vt3D1dVVs2bNUmxsrMLCwrRmzRrNnDlTJUqUkCSVKlVK06dP14oVK9SlSxdduXJFM2fOdPp11AAAAJD7nDaHtnfv3urdu3eGy0uXLq1FixZluLxRo0Zq1KhRTpQGAAAAE3HqHFoAAADgQRFoAQAAYGoEWgAAAJgagRYAAACmRqAFAACAqRFoAQAAYGoEWgAAAJgagRYAAACmRqAFAACAqRFoAQAAYGoEWgAAAJgagRYAAACmRqAFAACAqRFoAQAAYGoEWgAAAJgagRYAAACmRqAFAACAqRFoAQAAYGoEWgAAAJgagRYAAACmRqAFAACAqRFoAQAAYGoEWgAAAJgagRYAAACmRqAFAACAqRFoAQAAYGoEWgAAAJgagRYAAACmRqAFAACAqRFoAQAAYGoEWgAAAJgagRYAAACmRqAFAACAqRFoAQAAYGoEWgAAAJgagRYAAACmRqAFAACAqRFoAQAAYGoEWgAAAJgagRYAAACmRqAFAACAqRFoAQAAYGoEWgAAAJgagRYAAACmRqAFAACAqRFoAQAAYGp5ItBarVa1a9dOu3fvto1FREQoMDDQ7rFo0SLb8nXr1qlZs2YKDg5WeHi4Ll265IzSAQAA4GROD7RJSUl68803dfToUbvx6OhovfXWW9q+fbvt0blzZ0nSgQMHNGLECPXv319Lly7VtWvXNGzYMGeUDwAAACdzc+bOjx07prfeekuGYTgsi46OVq9eveTv7++wbNGiRWrdurU6deokSZowYYKaNGmimJgYPf744zldNgAAAPIQpwbaPXv2qHbt2ho4cKCqVatmG79x44YuXLigMmXKpPu6qKgovfrqq7bnxYsXV4kSJRQVFZXlQJuamno/pWfZ7f3cuT/DkAwjzWF9w8i92pCxjPqGvI2+mRN9Myf6Zk5m6Vtm63NqoO3atWu649HR0bJYLJozZ45++OEH+fr6qmfPnnr22WclSRcvXlSxYsXsXuPn56fz589nuYaDBw9mvfAHcOf+3AsX159//umw3tVr/oo7dTi3ysI95Pb3BNmDvpkTfTMn+mZOD0vfnBpoM3L8+HFZLBaVLVtWL774on766Se98847KlCggJo3b67ExER5eHjYvcbDw0NWqzXL+woKCpKrq2t2lZ6h1NRUHTx40GF/py8nys/Pz2H9Qj6FVKp0QI7XhbvLqG/I2+ibOdE3c6Jv5mSWvt2u817yZKDt1KmTmjRpIl9fX0nS008/rZMnT2rx4sVq3ry5PD09HcKr1WqVl5dXlvfl6uqaq428c38Wi2SxOJ6bZ7EoT3/BHjW5/T1B9qBv5kTfzIm+mdPD0rdsv8pBdlw+y2Kx2MLsbWXLltWFCxckSQEBAYqLi7NbHhcXl+4JZAAAAHi43VegrVixYrrB9cyZM3rmmWceuKipU6eqR48edmOHDx9W2bJlJUnBwcGKjIy0LTt37pzOnTun4ODgB943AAAAzCXTUw5Wr16tlStXSpIMw1B4eLjc3d3t1rl48WK2HCVt0qSJ5s6dq/nz56t58+bavn27Vq9erc8++0yS9Pzzz6tbt26qVq2agoKCNHbsWDVu3JhLdgEAADyCMh1omzdvrtOnT0u6dbmtatWqKX/+/HbreHt7q3nz5g9cVNWqVTV16lRNmzZNU6dOVcmSJfXhhx8qJCREkhQSEqL33ntP06ZN09WrV1WvXj2NGTPmgfcLAAAA88l0oM2fP7/69+8vSSpZsqTatGkjT0/PbCvkyJEjds+bNWumZs2aZbh+WFiYwsLCsm3/AAAAMKf7usrBs88+q1OnTumXX35RcnKyw/Lbd/ACAAAActp9Bdp58+Zp0qRJKlSokMO0A4vFQqAFAABArrmvQLtgwQINGjRIvXr1yu56AAAAgCy5r8t2JSUlqUWLFtldCwAAAJBl9xVo27dvry+//FKGYWR3PQAAAECW3NeUgxs3bmj58uVat26dSpUq5XA92tvXiwUAAABy2n0F2jJlyqhv377ZXQsAAACQZfcVaG9fjxYAAABwtvsKtMOGDbvr8nHjxt1XMQAAAEBW3ddJYXdKSUnRiRMn9PXXX6tIkSLZsUkAAAAgU+7rCG1GR2DnzZun33///YEKAgAAALIiW47Q3taqVSt9++232blJAAAA4K6yLdDGx8frq6++UuHChbNrkwAAAMA93deUg6effloWi8Vh3NPTUxEREQ9cFAAAAJBZ9xVo77xxgsVikbu7u8qVK6cCBQpkS2EAAABAZtxXoA0NDZUknTx5UtHR0UpLS9OTTz5JmAUAAECuu69Ae+3aNQ0bNkzfffedChUqpNTUVN28eVO1atXSzJkzVbBgweyuEwAAAEjXfZ0UFhERofPnz+vrr7/W7t27tXfvXq1du1bx8fHcVAEAAAC56r4C7X//+1+NHj1aZcuWtY2VK1dOI0eO1HfffZdtxQEAAAD3cl+B1tPTUy4uji+1WCxKTU194KIAAACAzLqvQNu0aVO9++67+uOPP2xjJ0+eVEREhBo1apRtxQEAAAD3cl8nhQ0aNEjh4eFq2bKlfHx8JElXr15Vw4YN9c4772RrgQAAAMDdZDnQnjp1SiVKlNDnn3+uI0eOKDo6Wp6enipTpoyeeuqpnKgRAAAAyFCmpxwYhqGIiAi1bt1aP//8syQpMDBQbdq00YoVK9SuXTuNHz9ehmHkWLEAAADAnTIdaD/77DN9/fXXmjlzpu3GCrfNmjVLM2fO1KpVq7R48eJsLxIAAADISKYD7VdffaV33nlHTZo0SXd506ZN9fbbbxNoAQAAkKsyHWjPnDmjqlWr3nWdOnXqKCYm5oGLAgAAADIr04HWz89PZ86cues658+fl6+v74PWBAAAAGRapgNt8+bNNX36dCUnJ6e7PCUlRTNmzFD9+vWzrTgAAADgXjJ92a5+/fqpS5cuCgsLU7du3VSlShUVLFhQV69e1a+//qpFixbp5s2bmjBhQk7WCwAAANjJdKD18fHRV199pUmTJmn8+PFKSEiQdOtyXgULFlSbNm30+uuvq2jRojlWLAAAAHCnLN1YwdfXVxERERo5cqRiYmJ07do1+fr66oknnpCrq2tO1QgAAABk6L5ufevh4cFdwQAAAJAnZPqkMAAAACAvItACAADA1Ai0AAAAMDUCLQAAAEyNQAsAAABTI9ACAADA1Ai0AAAAMDUCLQAAAEyNQAsAAABTI9ACAADA1Ai0AAAAMDUCLQAAAEwtTwRaq9Wqdu3aaffu3baxmJgY9ejRQ9WqVVObNm20fft2u9f8+OOPateunYKDg9W9e3fFxMTkdtkAAADIA5weaJOSkvTmm2/q6NGjtjHDMBQeHq6iRYtqxYoV6tixo/r376+zZ89Kks6ePavw8HCFhYVp+fLlKlKkiPr16yfDMJz1NgAAAOAkTg20x44d0z/+8Q/98ccfduO7du1STEyM3nvvPT311FPq06ePqlWrphUrVkiSli1bpipVqujll19W+fLlNW7cOJ05c0Z79uxxxtsAAACAEzk10O7Zs0e1a9fW0qVL7cajoqJUqVIleXt728Zq1Kih/fv325bXrFnTtszLy0uVK1e2LQcAAMCjw82ZO+/atWu647GxsSpWrJjdmJ+fn86fP5+p5VmRmpqa5dfcj9v7uXN/hiEZRprD+oaRe7UhYxn1DXkbfTMn+mZO9M2czNK3zNbn1ECbkYSEBHl4eNiNeXh4yGq1Zmp5Vhw8ePD+C70Pd+7PvXBx/fnnnw7rXb3mr7hTh3OrLNxDbn9PkD3omznRN3Oib+b0sPQtTwZaT09PXblyxW7MarUqX758tuV3hler1SofH58s7ysoKEiurq73XWtmpaam6uDBgw77O305UX5+fg7rF/IppFKlA3K8LtxdRn1D3kbfzIm+mRN9Myez9O12nfeSJwNtQECAjh07ZjcWFxdnm2YQEBCguLg4h+UVK1bM8r5cXV1ztZF37s9ikSwWx6nMFovy9BfsUZPb3xNkD/pmTvTNnOibOT0sfXP6ZbvSExwcrF9//VWJiYm2scjISAUHB9uWR0ZG2pYlJCTo0KFDtuUAAAB4dOTJQBsaGqrixYtr2LBhOnr0qObOnasDBw6oS5cukqTOnTtr3759mjt3ro4ePaphw4apVKlSql27tpMrBwAAQG7Lk4HW1dVVs2bNUmxsrMLCwrRmzRrNnDlTJUqUkCSVKlVK06dP14oVK9SlSxdduXJFM2fOlMVicXLlAAAAyG15Zg7tkSNH7J6XLl1aixYtynD9Ro0aqVGjRjldFgAAAPK4PHmEFgAAAMgsAi0AAABMjUALAAAAUyPQAgAAwNQItAAAADA1Ai0AAABMjUALAAAAUyPQAgAAwNQItAAAADA1Ai0AAABMjUALAAAAUyPQAgAAwNQItAAAADA1Ai0AAABMjUALAAAAUyPQAgAAwNQItAAAADA1N2cXgPRZLBb98edNh/GCXu4q7O3hhIoAAADyJgJtHhWflKKFO085jL/WqCyBFgAA4C+YcgAAAABTI9ACAADA1Ai0AAAAMDUCLQAAAEyNQAsAAABTI9ACAADA1Ai0AAAAMDUCLQAAAEyNQAsAAABTI9ACAADA1Ai0AAAAMDUCLQAAAEyNQAsAAABTI9ACAADA1NycXcAjLzVZSrqezgIj10sBAAAwIwKts6WlSOcPOI4bFXO/FgAAABNiygEAAABMjUALAAAAUyPQAgAAwNQItAAAADA1Ai0AAABMjUALAAAAUyPQAgAAwNQItAAAADA1Ai0AAABMjUALAAAAUyPQAgAAwNTydKD99ttvFRgYaPcYMGCAJOnQoUP6+9//ruDgYHXu3Fm//PKLk6sFAACAM+TpQHvs2DE1adJE27dvtz0iIiIUHx+v3r17q2bNmlq5cqVCQkLUp08fxcfHO7tkAAAA5DI3ZxdwN9HR0apQoYL8/f3txpcvXy5PT08NHjxYFotFI0aM0A8//KANGzYoLCzMSdXmPZfjrbqekOwwXtDLXYW9PZxQEQAAQPbL84H2b3/7m8N4VFSUatSoIYvFIkmyWCyqXr269u/fT6D9i+sJyZq99bjD+GuNyhJoAQDAQyPPBlrDMHTixAlt375dH3/8sVJTU9WqVSsNGDBAsbGxKleunN36fn5+Onr0aJb3k5qaml0lZ2o/d+7PkJHu+oYkw0hzHDcyX7ORmiwlXUt3PLfet9ll1DfkbfTNnOibOdE3czJL3zJbX54NtGfPnlVCQoI8PDw0ZcoUnT59WhEREUpMTLSN/5WHh4esVmuW93Pw4MHsKvm+9udbrIQSExMdVzSk5BuXHIatiTe1f//hTO3Lt1gJJZ78yWE8Jams9u+PzlzBkJT73xNkD/pmTvTNnOibOT0sfcuzgbZkyZLavXu3ChUqJIvFoooVKyotLU2DBg1SaGioQ3i1Wq3Kly9flvcTFBQkV1fX7Co7Q6mpqTp48KDD/k7HXsqgbkMel444jHq4VVG1atUytc+Mtu3m7pbpbTzqMuob8jb6Zk70zZzomzmZpW+367yXPBtoJcnX19fu+VNPPaWkpCT5+/srLi7ObllcXJyKFSuW5X24urrmaiPv3J9FlnTXS3/01vqZrTfjbWd+G7glt78nyB70zZzomznRN3N6WPqWZy/btW3bNtWuXVsJCQm2sd9++02+vr6qUaOGfv75ZxnGrfmnhmFo3759Cg4Odla5AAAAcJI8G2hDQkLk6empf/3rXzp+/Li2bt2qCRMm6JVXXlGrVq107do1jR07VseOHdPYsWOVkJCg1q1bO7tsAAAA5LI8G2gLFCig+fPn69KlS+rcubNGjBih5557Tq+88ooKFCigjz/+WJGRkQoLC1NUVJTmzp0rb29vZ5cNAACAXJan59CWL19en3zySbrLqlatqlWrVuVyRQAAAMhr8uwRWgAAACAzCLQAAAAwNQItAAAATI1ACwAAAFMj0AIAAMDUCLQAAAAwNQItAAAATI1ACwAAAFMj0AIAAMDUCLQAAAAwNQItAAAATI1ACwAAAFMj0AIAAMDUCLQAAAAwNQItAAAATI1ACwAAAFMj0AIAAMDUCLQAAAAwNQItAAAATI1ACwAAAFNzc3YBuA+XTto9vezmp+vJjv82Saa9AADgEUDiMRmLq7v+OH/Bbiy5iK/m/XjSYd0edUrlUlUAAADOQ6A1mXhrqhZu/NlurMdzFZxUDQAAgPMxhxYAAACmRqAFAACAqRFoAQAAYGoEWgAAAJgagRYAAACmxlUOHkEWNw/98edNu7GCXu4q7O3hpIoAAADuH4H2ERRvTdXCXafsxl5rVJZACwAATIkpBwAAADA1Ai0AAABMjSkHucin6GM6fTlRFsv/xpKzqwVJ17NnOwAAACZDoM1FCakWzd96TBbL/w6M96hT6sE3bBjS+QPpjD/94NvOivhLUuI1x/F8PpJ3kdytBQAAPDIItMg+idekHZMdx+sNJNACAIAcwxxaAAAAmBpHaGFeTHEAAAAi0OL/s1gsDjdbkLLphgsWi3TppP1YdoROpjgAAAARaB9dd1wVIT4pWQt3/uGwWrbccMF6U9rzsf0YoRMAAGQTAu2jKL2rIhgVM/3yy/FWXU9IdhgvaCmowg9aGwAAQBYRaJFl1xOSNXvrcYfx1/5WnEALAAByHYEW2cbi5qE/nurqMF7Q1S/TQTfDo79Zmcub3pxdiZPFAAB4SBFokW3iralauPFnh/HXniuT6UCb4dHfrMzlTW/OrsS8XQAAHlIEWvxPerfPTXU8WmpaOXW1BQAA4FQEWtyS0e1z0yrkfi2ZdFkFdT0rUxwelqstcP1dAADsEGhhChYZ+uN8nN1YsuGqeQ84xcGUuP4uAAB2TB1ok5KS9O6772rTpk3Kly+fXn75Zb388svOLgt3sLjnczhZrKCloAqnd+JWik+6Ux/ik5K1cOlyu7Ee//hHdpZ5/7JyxDSvHF3NK3Ugd9BvAA85UwfaCRMm6JdfftGnn36qs2fPasiQISpRooRatWrl7NLwF+mdLPbac2VUODKdo4w1hqc/9cF4OoeqywZZOWKaR46uXk40dP38BYfxgo8VVGHvXCsj70gv8GU17GXHNnJKHvneATCZvPxz7Q6mDbTx8fFatmyZ/v3vf6ty5cqqXLmyjh49qi+++IJAm40sbh6Ov+qXe/onkGVlu+kctZWkZIv7A233bttOd25tNlziK8O5vOkdhU61Zmqb2SqdH0jXk7w1O73pGs8/lfnpGg/TUb/0Al9Ww152bCOHZPgdFTdDAXAXefjn2p1MG2gPHz6slJQUhYSE2MZq1KihOXPmKC0tTS4uLk6s7uERn5SihV+l86v+BzyKmtElvnr8o3yWa8zsttOdW5sNl/i6bjXSD4fpHYUO7ZOpbWar9H4g1RieM9uV8uwPu0dZht/RrPwDBgDyMNMG2tjYWBUuXFgeHv+7NmnRokWVlJSkK1euqEiRu/8P1TAMSZLVapWrq2uO1ipJqampyufmIrfkG7JY/jeelpYmN1fH8J2V8dzehhlrliTD1UMnytofpfKxFJZPen8N0tJkWK1KTU2VdOt7cjMxUdcTHI+wphpu2ba/zLiW5q3rZdM52pbmLZ90tmFJS9Odf9VTM/iMUtNSZc1kHeltV1KW3ktO+WvfMvP3O73PNKPP81piiq4npjiMe7oUUlImt5EV127eTPd7V9DLQz7582dqG6lpqQ/c79yQ1b4hb6Bv5pSZvqX7cz6Xf8bfrvN2bsuIxbjXGnnU6tWrNXXqVH3//fe2sZiYGDVr1kxbt27VY489dtfXW61WHTx4MKfLBAAAwAMKCgqyO4h5J9MeofX09HQ4snD7eb58+e75ejc3NwUFBcnFxUWWvx4yBQAAQJ5gGMat37y63T2ymjbQBgQE6PLly0pJSbG9ydjYWOXLl08+Pj73fL2Li8tdkz4AAADMwbRnTlWsWFFubm7av3+/bSwyMtJ21BUAAACPBtMmPy8vL3Xq1EmjR4/WgQMHtHnzZi1YsEDdu3d3dmkAAADIRaY9KUySEhISNHr0aG3atEkFChRQr1691KNHD2eXBQAAgFxk6kALAAAAmHbKAQAAACARaAEAAGByBFoAAACYGoE2hyUlJWn48OGqWbOm6tevrwULFji7JNzBarWqXbt22r17t20sJiZGPXr0ULVq1dSmTRtt377d7jU//vij2rVrp+DgYHXv3l0xMTG5XfYj68KFCxowYIBCQ0PVoEEDjRs3TklJSZLoW1526tQp9erVSyEhIWrcuLHmzZtnW0bf8r7evXtr6NChtueHDh3S3//+dwUHB6tz58765Zdf7NZft26dmjVrpuDgYIWHh+vSpUu5XfIj7dtvv1VgYKDdY8CAAZIe3t4RaHPYhAkT9Msvv+jTTz/VqFGjNGPGDG3YsMHZZeH/S0pK0ptvvqmjR4/axgzDUHh4uIoWLaoVK1aoY8eO6t+/v86ePStJOnv2rMLDwxUWFqbly5erSJEi6tev3z3vM40HZxiGBgwYoISEBH3xxReaPHmyvv/+e02ZMoW+5WFpaWnq3bu3ChcurFWrVundd9/V7NmztXbtWvpmAuvXr9fWrVttz+Pj49W7d2/VrFlTK1euVEhIiPr06aP4+HhJ0oEDBzRixAj1799fS5cu1bVr1zRs2DBnlf9IOnbsmJo0aaLt27fbHhEREQ937wzkmJs3bxpBQUHGrl27bGMzZ840XnzxRSdWhduOHj1qdOjQwWjfvr1RoUIFW59+/PFHo1q1asbNmzdt67700kvGtGnTDMMwjClTptj1MD4+3ggJCbHrM3LGsWPHjAoVKhixsbG2sbVr1xr169enb3nYhQsXjDfeeMO4fv26bSw8PNwYNWoUfcvjLl++bDRs2NDo3LmzMWTIEMMwDGPZsmVG06ZNjbS0NMMwDCMtLc1o3ry5sWLFCsMwDGPQoEG2dQ3DMM6ePWsEBgYaf/zxR+6/gUfUW2+9ZXz44YcO4w9z7zhCm4MOHz6slJQUhYSE2MZq1KihqKgopaWlObEySNKePXtUu3ZtLV261G48KipKlSpVkre3t22sRo0atrvSRUVFqWbNmrZlXl5eqly5st1d65Az/P39NW/ePBUtWtRu/MaNG/QtDytWrJimTJmiAgUKyDAMRUZG6qefflJoaCh9y+M++OADdezYUeXKlbONRUVFqUaNGrJYLJIki8Wi6tWrZ9iz4sWLq0SJEoqKisrV2h9l0dHRKlOmjMP4w9w7Am0Oio2NVeHCheXh4WEbK1q0qJKSknTlyhXnFQZJUteuXTV8+HB5eXnZjcfGxqpYsWJ2Y35+fjp//nymliPn+Pj4qEGDBrbnaWlpWrRokerUqUPfTKJp06bq2rWrQkJC1LJlS/qWh+3cuVN79+5Vv3797Mbv1ZOLFy/SMycyDEMnTpzQ9u3b1bJlSzVr1kyTJk2S1Wp9qHvn5uwCHmYJCQl2YVaS7bnVanVGSciEjPp2u2f3Wo7cM3HiRB06dEjLly/XwoUL6ZsJTJs2TXFxcRo9erTGjRvH37c8KikpSaNGjdLIkSOVL18+u2X36kliYiI9c6KzZ8/aejRlyhSdPn1aERERSkxMfKh7R6DNQZ6eng5fgtvP7/wBgbzD09PT4Qi61Wq19Syjvvr4+ORWidCtMPvpp59q8uTJqlChAn0ziaCgIEm3AtPbb7+tzp07KyEhwW4d+uZ8M2bMUJUqVex+I3JbRj25V8/u/G0YckbJkiW1e/duFSpUSBaLRRUrVlRaWpoGDRqk0NDQh7Z3BNocFBAQoMuXLyslJUVubrc+6tjYWOXLl48fxnlYQECAjh07ZjcWFxdn+zVMQECA4uLiHJZXrFgx12p81I0ZM0aLFy/WxIkT1bJlS0n0LS+Li4vT/v371axZM9tYuXLllJycLH9/fx0/ftxhffrmXOvXr1dcXJztHJDbIWfjxo1q165duj25V8/8/f1zoXJIkq+vr93zp556SklJSfL3939oe8cc2hxUsWJFubm52Z28EBkZqaCgILm48NHnVcHBwfr111+VmJhoG4uMjFRwcLBteWRkpG1ZQkKCDh06ZFuOnDVjxgwtWbJEH330kdq2bWsbp2951+nTp9W/f39duHDBNvbLL7+oSJEiqlGjBn3Lgz7//HOtXbtWq1ev1urVq9W0aVM1bdpUq1evVnBwsH7++WfbpdMMw9C+ffsy7Nm5c+d07tw5epZLtm3bptq1a9v95uO3336Tr6+vatSo8dD2jlSVg7y8vNSpUyeNHj1aBw4c0ObNm7VgwQJ1797d2aXhLkJDQ1W8eHENGzZMR48e1dy5c3XgwAF16dJFktS5c2ft27dPc+fO1dGjRzVs2DCVKlVKtWvXdnLlD7/o6GjNmjVLr776qmrUqKHY2Fjbg77lXUFBQapcubKGDx+uY8eOaevWrZo4caL69u1L3/KokiVLqnTp0rZH/vz5lT9/fpUuXVqtWrXStWvXNHbsWB07dkxjx45VQkKCWrduLUl6/vnn9Z///EfLli3T4cOHNXjwYDVu3FiPP/64k9/VoyEkJESenp7617/+pePHj2vr1q2aMGGCXnnllYe7d868ZtijID4+3hg8eLBRrVo1o379+sYnn3zi7JKQjr9eh9YwDOPkyZPGCy+8YFSpUsVo27atsWPHDrv1t2zZYrRo0cKoWrWq8dJLL5niGn0Pg48//tioUKFCug/DoG952fnz543w8HCjevXqRr169YzZs2fbroVJ3/K+IUOG2F2fNCoqyujUqZMRFBRkdOnSxfj111/t1l+xYoXRqFEjo1q1akZ4eLhx6dKl3C75kfb7778bPXr0MKpVq2bUq1fPmD59uu3v28PaO4thcLsVAAAAmBdTDgAAAGBqBFoAAACYGoEWAAAApkagBQAAgKkRaAEAAGBqBFoAAACYGoEWAAAApkagBQAAgKm5ObsAAICjpk2b6syZMw7j1atX1+LFi51QEQDkXQRaAMijhg8frjZt2tiNubu7O6kaAMi7CLQAkEcVLFhQ/v7+zi4DAPI85tACgMncuHFDw4YNU926dVWlShW1atVKmzdvti0PDAzU1KlTVbt2bfXt21eStHfvXoWFhalq1apq3769Nm7c6KzyASDbcYQWAExm7NixOnHihBYsWCAvLy/NmzdPI0aMUMOGDeXh4SFJ+v7777V48WKlpaUpNjZWffr00cCBA9WgQQPt379fQ4cOlZ+fn2rWrOnkdwMAD85iGIbh7CIAAPaaNm2q2NhYubnZH3fYsWOHNmzYoCpVqqhChQqSpOPHj6t169basmWLihcvrsDAQI0ePVrPP/+8JGnKlCmKjo7W9OnTbdsZP368zpw5YzcGAGbFEVoAyKMGDBigFi1a2I15eXmpU6dO2rx5s7766isdP35cv/76qyQpNTXVtl7JkiVtfz5+/Li+//57hYSE2MaSk5P15JNP5vA7AIDcQaAFgDzKz89PpUuXdhgfNGiQfv75Z3Xs2FHPP/+8/P399dxzz9mt4+npaftzSkqK2rdvb5tPe9udR38BwKz4aQYAJnLjxg2tW7dOX331lapWrSpJ2rp1qyQpoxlkTz75pH7++We7cLxgwQJZrVaHkAsAZsRVDgDARDw8POTl5aVNmzbp9OnT2rZtm9577z1JktVqTfc1Xbt21S+//KLJkyfr5MmTWrt2rT766COVKFEiN0sHgBxDoAUAE/Hw8NDEiRO1ceNGtW3bVuPHj9drr70mf39//fbbb+m+pmTJkpozZ462bdumdu3aacqUKRo6dKg6dOiQy9UDQM7gKgcAAAAwNY7QAgAAwNQItAAAADA1Ai0AAABMjUALAAAAUyPQAgAAwNQItAAAADA1Ai0AAABMjUALAAAAUyPQAgAAwNQItAAAADA1Ai0AAABM7f8B18sIrBaqThkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Age histogram grouped by Survive \n",
    "# Set the style of the visualization\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Create a histogram of the 'Age' variable split by 'Survived'\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(data=ini_train_set, x='Fare', hue='Survived', bins=100, alpha=0.6)\n",
    "plt.title('Histogram of Fare by Survived')\n",
    "plt.xlabel('Fare')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Survived', labels=['Yes', 'No'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Fare             0\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no of empty rows w.r.t columns in training set\n",
    "ini_train_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId     0\n",
       "Pclass          0\n",
       "Name            0\n",
       "Sex             0\n",
       "Age            86\n",
       "SibSp           0\n",
       "Parch           0\n",
       "Fare            1\n",
       "Embarked        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no of empty rows w.r.t columns in test set\n",
    "test_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the empty spaces in the age column with the median value of the column\n",
    "ini_train_set['Age'].fillna(ini_train_set['Age'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the empty spaces in the embarked column with the mode value of the column\n",
    "ini_train_set['Embarked'].fillna(ini_train_set['Embarked'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the empty spaces in the age column with the median value of the column\n",
    "test_set['Age'].fillna(test_set['Age'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the empty spaces in the fare column with the median value of the column\n",
    "test_set['Fare'].fillna(test_set['Fare'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Fare           0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ini_train_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Fare           0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing male with 0 and female with 1 in training set since female survived the most\n",
    "ini_train_set.replace({'Sex':{'male':0,'female':1}},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing male with 0 and female with 1 in test set since female survived the most\n",
    "test_set.replace({'Sex':{'male':0,'female':1}},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the c with 1 and Q with 0 and S with 0 since C has survived more in training set\n",
    "ini_train_set.replace({'Embarked':{'C':1,'Q':0,'S':0}},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the c with 1 and Q with 0 and S with 0 since C has survived more in test set\n",
    "test_set.replace({'Embarked':{'C':1,'Q':0,'S':0}},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the parch 0,1,2,3,4,5,6 with 0,1,0,1,0,0,0 respectively sice parch 1,3 survived the most in training set\n",
    "ini_train_set.replace({'Parch': {0: 0, 1: 1, 2: 0, 3: 1, 4: 0, 5: 0, 6: 0}}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the parch 0,1,2,3,4,5,6 with 0,1,0,1,0,0,0 respectively in test set\n",
    "test_set.replace({'Parch': {0: 0, 1: 1, 2: 0, 3: 1, 4: 0, 5: 0, 6: 0}}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repalcing the pclass 1,2,3 with 1,0,0 respectively since pclass 1 survived the most in training set\n",
    "ini_train_set.replace({'Pclass':{1:1, 2:0, 3:0}},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the pclass 1,2,3 with 1,0,0 respectively in the test set same as the training set\n",
    "test_set.replace({'Pclass':{1:1, 2:0, 3:0}},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing sibsp 0,1,2,3,4,5,8 with 0,1,1,0,0,0,0 respectively since sibsp 1,2 survived the most in the training set \n",
    "ini_train_set.replace({'SibSp':{0:0,1:1, 2:1, 3:0,4:0,5:0,8:0}},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing sibsp 0,1,2,3,4,5,8 with 0,1,1,0,0,0,0 respectively in the test set same as training set\n",
    "test_set.replace({'SibSp':{0:0,1:1, 2:1, 3:0,4:0,5:0,8:0}},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values in the 'Age' column with 1 where the age is less than or equal to 15 or greater than 65 in training set \n",
    "ini_train_set.loc[(ini_train_set['Age'] <=15) | (ini_train_set['Age']>=65) ,'Age'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values in the 'Age' column with 1 where the age is less than or equal to 15 or greater than 65\n",
    "test_set.loc[(test_set['Age'] <= 15)| (ini_train_set['Age']>=65), 'Age'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repalce values in the age column with 0 if the age is greater than 15\n",
    "ini_train_set.loc[(ini_train_set['Age'] > 15), 'Age'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repalce values in the age column with 0 if the age is greater than 15\n",
    "test_set.loc[(test_set['Age'] > 15), 'Age'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11    0.0\n",
      "12    0.0\n",
      "13    0.0\n",
      "14    1.0\n",
      "15    0.0\n",
      "16    1.0\n",
      "17    0.0\n",
      "18    0.0\n",
      "19    0.0\n",
      "20    0.0\n",
      "21    0.0\n",
      "22    1.0\n",
      "23    0.0\n",
      "24    1.0\n",
      "25    0.0\n",
      "26    0.0\n",
      "27    0.0\n",
      "28    0.0\n",
      "29    0.0\n",
      "30    0.0\n",
      "31    0.0\n",
      "32    0.0\n",
      "33    1.0\n",
      "34    0.0\n",
      "35    0.0\n",
      "36    0.0\n",
      "37    0.0\n",
      "38    0.0\n",
      "39    1.0\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(ini_train_set.Age[11:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the values in the fare column with 0 if the fare is less than 50\n",
    "ini_train_set.loc[(ini_train_set['Fare'] <50), 'Fare'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the values in the fare column with 0 if the fare is less than 50\n",
    "test_set.loc[(test_set['Fare'] < 50), 'Fare'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the values in the fare column with 1 if the values are greater than equal to 50\n",
    "ini_train_set.loc[(ini_train_set['Fare'] >=50), 'Fare'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the values in the fare column with 1 if the values are greater than equal to 50\n",
    "test_set.loc[(test_set['Fare'] >= 50), 'Fare'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     1.0\n",
      "2     0.0\n",
      "3     1.0\n",
      "4     0.0\n",
      "5     0.0\n",
      "6     1.0\n",
      "7     0.0\n",
      "8     0.0\n",
      "9     0.0\n",
      "10    0.0\n",
      "11    0.0\n",
      "12    0.0\n",
      "13    0.0\n",
      "14    0.0\n",
      "15    0.0\n",
      "16    0.0\n",
      "17    0.0\n",
      "18    0.0\n",
      "19    0.0\n",
      "20    0.0\n",
      "21    0.0\n",
      "22    0.0\n",
      "23    0.0\n",
      "24    0.0\n",
      "25    0.0\n",
      "26    0.0\n",
      "27    1.0\n",
      "28    0.0\n",
      "29    0.0\n",
      "30    0.0\n",
      "31    1.0\n",
      "32    0.0\n",
      "33    0.0\n",
      "34    1.0\n",
      "35    1.0\n",
      "36    0.0\n",
      "37    0.0\n",
      "38    0.0\n",
      "39    0.0\n",
      "Name: Fare, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(ini_train_set.Fare[1:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = ['Sex', 'Embarked', 'Parch', 'Pclass', 'SibSp','Age','Fare']  # List of feature column names\n",
    "Y = ini_train_set['Survived']  # Target variable\n",
    "X = ini_train_set[X_]  # Feature variables\n",
    "X_test = test_set[X_]  # test feature variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting data into training set and cross validation set\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, Y, test_size=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scaling (standardizing) the features in the training set X_train and fitting the scaler to it\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transforming the cross-validation set X_cv using the scaler fitted on the training set\n",
    "X_cv = scaler.transform(X_cv)\n",
    "\n",
    "# Transforming the test set X_test using the same scaler\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((882, 7), (9, 7), (882,), (9,), (418, 7))"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the shapes of various datasets to check dimensions\n",
    "\n",
    "# Output the shape of the training set X_train\n",
    "X_train.shape\n",
    "\n",
    "# Output the shape of the cross-validation set X_cv\n",
    "X_cv.shape\n",
    "\n",
    "# Output the shape of the training labels y_train\n",
    "y_train.shape\n",
    "\n",
    "# Output the shape of the cross-validation labels y_cv\n",
    "y_cv.shape\n",
    "\n",
    "# Output the shape of the test set X_test\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Sequential model using Keras API\n",
    "model = tf.keras.Sequential([\n",
    "    # First hidden layer with 256 neurons, ReLU activation function, and L2 regularization\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    \n",
    "    # Dropout layer with a dropout rate of 0.5 to prevent overfitting\n",
    "    \n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    # Second hidden layer with 128 neurons, ReLU activation function, and L2 regularization\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    \n",
    "    # Dropout layer with a dropout rate of 0.5\n",
    "    \n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    # Third hidden layer with 64 neurons, ReLU activation function, and L2 regularization\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    \n",
    "    # Dropout layer with a dropout rate of 0.5\n",
    "    \n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    # Fourth hidden layer with 32 neurons, ReLU activation function, and L2 regularization\n",
    "    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    \n",
    "    # Dropout layer with a dropout rate of 0.5\n",
    "    \n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    # Output layer with 1 neuron and sigmoid activation function for binary classification\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with specified optimizer, loss function, and evaluation metrics\n",
    "model.compile(\n",
    "    optimizer='adam',               # Adam optimizer, which is commonly used for training neural networks\n",
    "    loss='binary_crossentropy',    # Binary cross-entropy loss function for binary classification tasks\n",
    "    metrics=['accuracy']           # Evaluation metric to monitor during training, accuracy in this case\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7706 - loss: 0.5497\n",
      "Epoch 2/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7822 - loss: 0.5276\n",
      "Epoch 3/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7740 - loss: 0.5393\n",
      "Epoch 4/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7871 - loss: 0.5342\n",
      "Epoch 5/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7933 - loss: 0.5038\n",
      "Epoch 6/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7889 - loss: 0.5240\n",
      "Epoch 7/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7893 - loss: 0.5072\n",
      "Epoch 8/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7788 - loss: 0.5403\n",
      "Epoch 9/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8102 - loss: 0.5063\n",
      "Epoch 10/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7749 - loss: 0.5339\n",
      "Epoch 11/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7609 - loss: 0.5602\n",
      "Epoch 12/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7952 - loss: 0.5444\n",
      "Epoch 13/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7537 - loss: 0.5545\n",
      "Epoch 14/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7746 - loss: 0.5384\n",
      "Epoch 15/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7931 - loss: 0.5233\n",
      "Epoch 16/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7895 - loss: 0.5183\n",
      "Epoch 17/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7814 - loss: 0.5538\n",
      "Epoch 18/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7784 - loss: 0.5520\n",
      "Epoch 19/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7764 - loss: 0.5136\n",
      "Epoch 20/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7610 - loss: 0.5415\n",
      "Epoch 21/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8009 - loss: 0.5080\n",
      "Epoch 22/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7877 - loss: 0.5115\n",
      "Epoch 23/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7740 - loss: 0.5269\n",
      "Epoch 24/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7657 - loss: 0.5450\n",
      "Epoch 25/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7533 - loss: 0.5354\n",
      "Epoch 26/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7908 - loss: 0.5384\n",
      "Epoch 27/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7826 - loss: 0.5552\n",
      "Epoch 28/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7837 - loss: 0.5346\n",
      "Epoch 29/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7777 - loss: 0.5302\n",
      "Epoch 30/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8060 - loss: 0.5403\n",
      "Epoch 31/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7868 - loss: 0.5576\n",
      "Epoch 32/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8080 - loss: 0.5179\n",
      "Epoch 33/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7857 - loss: 0.5237\n",
      "Epoch 34/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7688 - loss: 0.5512\n",
      "Epoch 35/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7731 - loss: 0.5485\n",
      "Epoch 36/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7771 - loss: 0.5310\n",
      "Epoch 37/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7719 - loss: 0.5457\n",
      "Epoch 38/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7739 - loss: 0.5408\n",
      "Epoch 39/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7806 - loss: 0.5382\n",
      "Epoch 40/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7751 - loss: 0.5678\n",
      "Epoch 41/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7989 - loss: 0.5044\n",
      "Epoch 42/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7806 - loss: 0.5284\n",
      "Epoch 43/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7933 - loss: 0.5129\n",
      "Epoch 44/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7978 - loss: 0.5291\n",
      "Epoch 45/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7955 - loss: 0.5147\n",
      "Epoch 46/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8030 - loss: 0.5076\n",
      "Epoch 47/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7724 - loss: 0.5215\n",
      "Epoch 48/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7662 - loss: 0.5616\n",
      "Epoch 49/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8151 - loss: 0.4998\n",
      "Epoch 50/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7872 - loss: 0.5200\n",
      "Epoch 51/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7708 - loss: 0.5516\n",
      "Epoch 52/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7827 - loss: 0.5246\n",
      "Epoch 53/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7865 - loss: 0.5207\n",
      "Epoch 54/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7618 - loss: 0.5433\n",
      "Epoch 55/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7775 - loss: 0.5094\n",
      "Epoch 56/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7787 - loss: 0.5185\n",
      "Epoch 57/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7828 - loss: 0.5205\n",
      "Epoch 58/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7724 - loss: 0.5392\n",
      "Epoch 59/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7871 - loss: 0.5367\n",
      "Epoch 60/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7652 - loss: 0.5367\n",
      "Epoch 61/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7590 - loss: 0.5424\n",
      "Epoch 62/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7780 - loss: 0.5395\n",
      "Epoch 63/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7704 - loss: 0.5474\n",
      "Epoch 64/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7881 - loss: 0.5382\n",
      "Epoch 65/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7728 - loss: 0.5689\n",
      "Epoch 66/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 0.5103\n",
      "Epoch 67/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7632 - loss: 0.5433\n",
      "Epoch 68/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7988 - loss: 0.5337\n",
      "Epoch 69/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7796 - loss: 0.5175\n",
      "Epoch 70/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7633 - loss: 0.5625\n",
      "Epoch 71/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7825 - loss: 0.5405\n",
      "Epoch 72/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7630 - loss: 0.5733\n",
      "Epoch 73/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7997 - loss: 0.5183\n",
      "Epoch 74/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7634 - loss: 0.5510\n",
      "Epoch 75/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7664 - loss: 0.5319\n",
      "Epoch 76/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7544 - loss: 0.5460\n",
      "Epoch 77/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7725 - loss: 0.5349\n",
      "Epoch 78/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7556 - loss: 0.5526\n",
      "Epoch 79/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7751 - loss: 0.5320\n",
      "Epoch 80/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7309 - loss: 0.5566\n",
      "Epoch 81/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8232 - loss: 0.5104\n",
      "Epoch 82/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7624 - loss: 0.5485\n",
      "Epoch 83/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7870 - loss: 0.5327\n",
      "Epoch 84/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7643 - loss: 0.5303\n",
      "Epoch 85/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7954 - loss: 0.5220\n",
      "Epoch 86/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7904 - loss: 0.5055\n",
      "Epoch 87/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7514 - loss: 0.5545\n",
      "Epoch 88/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8124 - loss: 0.5110\n",
      "Epoch 89/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7757 - loss: 0.5363\n",
      "Epoch 90/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7616 - loss: 0.5618\n",
      "Epoch 91/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7857 - loss: 0.5447\n",
      "Epoch 92/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7863 - loss: 0.5282\n",
      "Epoch 93/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7760 - loss: 0.5577\n",
      "Epoch 94/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8109 - loss: 0.5025\n",
      "Epoch 95/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7360 - loss: 0.5718\n",
      "Epoch 96/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7838 - loss: 0.5228\n",
      "Epoch 97/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7610 - loss: 0.5561\n",
      "Epoch 98/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7665 - loss: 0.5488\n",
      "Epoch 99/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7736 - loss: 0.5431\n",
      "Epoch 100/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8229 - loss: 0.5033\n",
      "Epoch 101/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7642 - loss: 0.5512\n",
      "Epoch 102/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7640 - loss: 0.5331\n",
      "Epoch 103/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7577 - loss: 0.5632\n",
      "Epoch 104/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8116 - loss: 0.4968\n",
      "Epoch 105/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7907 - loss: 0.5484\n",
      "Epoch 106/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7520 - loss: 0.5548\n",
      "Epoch 107/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7429 - loss: 0.5911\n",
      "Epoch 108/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7658 - loss: 0.5641\n",
      "Epoch 109/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7786 - loss: 0.5323\n",
      "Epoch 110/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7808 - loss: 0.5389\n",
      "Epoch 111/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7891 - loss: 0.5203\n",
      "Epoch 112/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8011 - loss: 0.5163\n",
      "Epoch 113/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7591 - loss: 0.5603\n",
      "Epoch 114/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7528 - loss: 0.5453\n",
      "Epoch 115/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7819 - loss: 0.5193\n",
      "Epoch 116/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7927 - loss: 0.5227\n",
      "Epoch 117/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7541 - loss: 0.5566\n",
      "Epoch 118/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7951 - loss: 0.5417\n",
      "Epoch 119/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7668 - loss: 0.5340\n",
      "Epoch 120/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7790 - loss: 0.5406\n",
      "Epoch 121/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7855 - loss: 0.5132\n",
      "Epoch 122/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7888 - loss: 0.5143\n",
      "Epoch 123/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7657 - loss: 0.5563\n",
      "Epoch 124/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7846 - loss: 0.5316\n",
      "Epoch 125/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7904 - loss: 0.5253\n",
      "Epoch 126/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7988 - loss: 0.5025\n",
      "Epoch 127/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7616 - loss: 0.5484\n",
      "Epoch 128/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7797 - loss: 0.5360\n",
      "Epoch 129/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7628 - loss: 0.5482\n",
      "Epoch 130/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7980 - loss: 0.5180\n",
      "Epoch 131/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7859 - loss: 0.5395\n",
      "Epoch 132/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7948 - loss: 0.5130\n",
      "Epoch 133/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7939 - loss: 0.5287\n",
      "Epoch 134/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7665 - loss: 0.5313\n",
      "Epoch 135/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8083 - loss: 0.4889\n",
      "Epoch 136/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7850 - loss: 0.5412\n",
      "Epoch 137/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7818 - loss: 0.5277\n",
      "Epoch 138/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7661 - loss: 0.5480\n",
      "Epoch 139/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7596 - loss: 0.5334\n",
      "Epoch 140/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7791 - loss: 0.5192\n",
      "Epoch 141/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7946 - loss: 0.5163\n",
      "Epoch 142/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7877 - loss: 0.5478\n",
      "Epoch 143/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7830 - loss: 0.5269\n",
      "Epoch 144/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7175 - loss: 0.5794\n",
      "Epoch 145/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7629 - loss: 0.5526\n",
      "Epoch 146/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7521 - loss: 0.5454\n",
      "Epoch 147/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7846 - loss: 0.5253\n",
      "Epoch 148/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8056 - loss: 0.5129\n",
      "Epoch 149/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7665 - loss: 0.5303\n",
      "Epoch 150/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7841 - loss: 0.5381\n",
      "Epoch 151/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8082 - loss: 0.4984\n",
      "Epoch 152/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7997 - loss: 0.5162\n",
      "Epoch 153/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7804 - loss: 0.5138\n",
      "Epoch 154/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7387 - loss: 0.5657\n",
      "Epoch 155/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7762 - loss: 0.5499\n",
      "Epoch 156/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7954 - loss: 0.5297\n",
      "Epoch 157/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7758 - loss: 0.5285\n",
      "Epoch 158/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7596 - loss: 0.5659\n",
      "Epoch 159/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7690 - loss: 0.5094\n",
      "Epoch 160/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7379 - loss: 0.5596\n",
      "Epoch 161/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8030 - loss: 0.4835\n",
      "Epoch 162/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7712 - loss: 0.5272\n",
      "Epoch 163/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7718 - loss: 0.5435\n",
      "Epoch 164/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7906 - loss: 0.5322\n",
      "Epoch 165/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7899 - loss: 0.5106\n",
      "Epoch 166/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7951 - loss: 0.5127\n",
      "Epoch 167/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7806 - loss: 0.5534\n",
      "Epoch 168/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7688 - loss: 0.5359\n",
      "Epoch 169/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7768 - loss: 0.5443\n",
      "Epoch 170/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7662 - loss: 0.5526\n",
      "Epoch 171/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7775 - loss: 0.5459\n",
      "Epoch 172/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7867 - loss: 0.5074\n",
      "Epoch 173/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7717 - loss: 0.5335\n",
      "Epoch 174/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7759 - loss: 0.5206\n",
      "Epoch 175/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7868 - loss: 0.5161\n",
      "Epoch 176/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7808 - loss: 0.5381\n",
      "Epoch 177/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8117 - loss: 0.4934\n",
      "Epoch 178/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7963 - loss: 0.5318\n",
      "Epoch 179/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7922 - loss: 0.5236\n",
      "Epoch 180/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7604 - loss: 0.5376\n",
      "Epoch 181/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7564 - loss: 0.5280\n",
      "Epoch 182/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7698 - loss: 0.5462\n",
      "Epoch 183/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7859 - loss: 0.5477\n",
      "Epoch 184/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7743 - loss: 0.5322\n",
      "Epoch 185/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7994 - loss: 0.5269\n",
      "Epoch 186/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7764 - loss: 0.5137\n",
      "Epoch 187/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7901 - loss: 0.5152\n",
      "Epoch 188/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8082 - loss: 0.5053\n",
      "Epoch 189/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7905 - loss: 0.5230\n",
      "Epoch 190/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7713 - loss: 0.5596\n",
      "Epoch 191/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7864 - loss: 0.5380\n",
      "Epoch 192/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7913 - loss: 0.5351\n",
      "Epoch 193/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7770 - loss: 0.5403\n",
      "Epoch 194/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7801 - loss: 0.5236\n",
      "Epoch 195/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8009 - loss: 0.5146\n",
      "Epoch 196/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7593 - loss: 0.5538\n",
      "Epoch 197/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7944 - loss: 0.5214\n",
      "Epoch 198/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7596 - loss: 0.5655\n",
      "Epoch 199/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7915 - loss: 0.5347\n",
      "Epoch 200/200\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7826 - loss: 0.5314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x245ec752990>"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on the training data\n",
    "model.fit(\n",
    "    X_train,             # Input features (X_train)\n",
    "    y_train,             # Target labels (y_train)\n",
    "    epochs=200,          # Number of training epochs (iterations over the entire dataset)\n",
    "    batch_size=4,        # Number of samples per gradient update\n",
    "    verbose=1            # Verbosity mode (1: progress bar, 0: silent)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.8889 - loss: 0.5282\n",
      "Test Accuracy: 0.8888888955116272\n",
      "Test Loss: 0.528242290019989\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's performance on the cross-validation dataset\n",
    "loss, accuracy = model.evaluate(X_cv, y_cv, verbose=1)\n",
    "\n",
    "# Print the test accuracy and test loss\n",
    "print(f\"Test Accuracy: {accuracy}\")  # Print the accuracy achieved by the model on the cross-validation set\n",
    "print(f\"Test Loss: {loss}\")           # Print the loss value obtained by the model on the cross-validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(418,)"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict probabilities of survival for the test set using the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predicted probabilities to binary predictions based on a threshold of 0.8\n",
    "# If the predicted probability is greater than 0.8, classify as survived (1), otherwise classify as not survived (0)\n",
    "y_pred = (y_pred > 0.8).astype(int).ravel()\n",
    "\n",
    "# Shape of the predicted labels array\n",
    "y_pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         0\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         0\n",
      "5            897         0\n",
      "6            898         0\n",
      "7            899         0\n",
      "8            900         0\n",
      "9            901         0\n",
      "10           902         0\n",
      "11           903         0\n",
      "12           904         1\n",
      "13           905         0\n",
      "14           906         1\n",
      "15           907         0\n",
      "16           908         0\n",
      "17           909         0\n",
      "18           910         0\n",
      "19           911         0\n",
      "20           912         0\n",
      "21           913         0\n",
      "22           914         0\n",
      "23           915         0\n",
      "24           916         1\n",
      "25           917         0\n",
      "26           918         1\n",
      "27           919         0\n",
      "28           920         0\n",
      "29           921         0\n",
      "30           922         0\n",
      "31           923         0\n",
      "32           924         0\n",
      "33           925         0\n",
      "34           926         0\n",
      "35           927         0\n",
      "36           928         0\n",
      "37           929         0\n",
      "38           930         0\n",
      "39           931         0\n",
      "40           932         0\n",
      "41           933         0\n",
      "42           934         0\n",
      "43           935         0\n",
      "44           936         1\n",
      "45           937         0\n",
      "46           938         0\n",
      "47           939         0\n",
      "48           940         1\n",
      "49           941         0\n",
      "50           942         0\n",
      "51           943         0\n",
      "52           944         0\n",
      "53           945         0\n",
      "54           946         0\n",
      "55           947         0\n",
      "56           948         0\n",
      "57           949         0\n",
      "58           950         0\n",
      "59           951         1\n",
      "60           952         0\n",
      "61           953         0\n",
      "62           954         0\n",
      "63           955         0\n",
      "64           956         0\n",
      "65           957         0\n",
      "66           958         0\n",
      "67           959         0\n",
      "68           960         0\n",
      "69           961         1\n",
      "70           962         0\n",
      "71           963         0\n",
      "72           964         0\n",
      "73           965         0\n",
      "74           966         1\n",
      "75           967         0\n",
      "76           968         0\n",
      "77           969         0\n",
      "78           970         0\n",
      "79           971         0\n",
      "80           972         0\n",
      "81           973         0\n",
      "82           974         0\n",
      "83           975         0\n",
      "84           976         0\n",
      "85           977         0\n",
      "86           978         0\n",
      "87           979         0\n",
      "88           980         0\n",
      "89           981         0\n",
      "90           982         0\n",
      "91           983         0\n",
      "92           984         1\n",
      "93           985         0\n",
      "94           986         0\n",
      "95           987         0\n",
      "96           988         1\n",
      "97           989         0\n",
      "98           990         0\n",
      "99           991         0\n",
      "100          992         1\n",
      "101          993         0\n",
      "102          994         0\n",
      "103          995         0\n",
      "104          996         0\n",
      "105          997         0\n",
      "106          998         0\n",
      "107          999         0\n",
      "108         1000         0\n",
      "109         1001         0\n",
      "110         1002         0\n",
      "111         1003         0\n",
      "112         1004         1\n",
      "113         1005         0\n",
      "114         1006         1\n",
      "115         1007         0\n",
      "116         1008         0\n",
      "117         1009         0\n",
      "118         1010         0\n",
      "119         1011         0\n",
      "120         1012         0\n",
      "121         1013         0\n",
      "122         1014         1\n",
      "123         1015         0\n",
      "124         1016         0\n",
      "125         1017         0\n",
      "126         1018         0\n",
      "127         1019         0\n",
      "128         1020         0\n",
      "129         1021         0\n",
      "130         1022         0\n",
      "131         1023         0\n",
      "132         1024         0\n",
      "133         1025         0\n",
      "134         1026         0\n",
      "135         1027         0\n",
      "136         1028         0\n",
      "137         1029         0\n",
      "138         1030         0\n",
      "139         1031         0\n",
      "140         1032         0\n",
      "141         1033         0\n",
      "142         1034         0\n",
      "143         1035         0\n",
      "144         1036         0\n",
      "145         1037         0\n",
      "146         1038         0\n",
      "147         1039         0\n",
      "148         1040         0\n",
      "149         1041         0\n",
      "150         1042         1\n",
      "151         1043         0\n",
      "152         1044         0\n",
      "153         1045         0\n",
      "154         1046         0\n",
      "155         1047         0\n",
      "156         1048         0\n",
      "157         1049         0\n",
      "158         1050         0\n",
      "159         1051         0\n",
      "160         1052         0\n",
      "161         1053         0\n",
      "162         1054         0\n",
      "163         1055         0\n",
      "164         1056         0\n",
      "165         1057         0\n",
      "166         1058         0\n",
      "167         1059         0\n",
      "168         1060         1\n",
      "169         1061         0\n",
      "170         1062         0\n",
      "171         1063         0\n",
      "172         1064         0\n",
      "173         1065         0\n",
      "174         1066         0\n",
      "175         1067         0\n",
      "176         1068         0\n",
      "177         1069         0\n",
      "178         1070         0\n",
      "179         1071         1\n",
      "180         1072         0\n",
      "181         1073         0\n",
      "182         1074         1\n",
      "183         1075         0\n",
      "184         1076         1\n",
      "185         1077         0\n",
      "186         1078         0\n",
      "187         1079         0\n",
      "188         1080         0\n",
      "189         1081         0\n",
      "190         1082         0\n",
      "191         1083         0\n",
      "192         1084         0\n",
      "193         1085         0\n",
      "194         1086         0\n",
      "195         1087         0\n",
      "196         1088         0\n",
      "197         1089         0\n",
      "198         1090         0\n",
      "199         1091         0\n",
      "200         1092         0\n",
      "201         1093         0\n",
      "202         1094         0\n",
      "203         1095         0\n",
      "204         1096         0\n",
      "205         1097         0\n",
      "206         1098         0\n",
      "207         1099         0\n",
      "208         1100         1\n",
      "209         1101         0\n",
      "210         1102         0\n",
      "211         1103         0\n",
      "212         1104         0\n",
      "213         1105         0\n",
      "214         1106         0\n",
      "215         1107         0\n",
      "216         1108         0\n",
      "217         1109         0\n",
      "218         1110         1\n",
      "219         1111         0\n",
      "220         1112         0\n",
      "221         1113         0\n",
      "222         1114         0\n",
      "223         1115         0\n",
      "224         1116         1\n",
      "225         1117         0\n",
      "226         1118         0\n",
      "227         1119         0\n",
      "228         1120         0\n",
      "229         1121         0\n",
      "230         1122         0\n",
      "231         1123         0\n",
      "232         1124         0\n",
      "233         1125         0\n",
      "234         1126         0\n",
      "235         1127         0\n",
      "236         1128         0\n",
      "237         1129         0\n",
      "238         1130         0\n",
      "239         1131         1\n",
      "240         1132         1\n",
      "241         1133         0\n",
      "242         1134         0\n",
      "243         1135         0\n",
      "244         1136         0\n",
      "245         1137         0\n",
      "246         1138         0\n",
      "247         1139         0\n",
      "248         1140         0\n",
      "249         1141         0\n",
      "250         1142         0\n",
      "251         1143         0\n",
      "252         1144         0\n",
      "253         1145         0\n",
      "254         1146         0\n",
      "255         1147         0\n",
      "256         1148         0\n",
      "257         1149         0\n",
      "258         1150         0\n",
      "259         1151         0\n",
      "260         1152         0\n",
      "261         1153         0\n",
      "262         1154         0\n",
      "263         1155         0\n",
      "264         1156         0\n",
      "265         1157         0\n",
      "266         1158         0\n",
      "267         1159         0\n",
      "268         1160         0\n",
      "269         1161         0\n",
      "270         1162         0\n",
      "271         1163         0\n",
      "272         1164         1\n",
      "273         1165         0\n",
      "274         1166         0\n",
      "275         1167         0\n",
      "276         1168         0\n",
      "277         1169         0\n",
      "278         1170         0\n",
      "279         1171         0\n",
      "280         1172         0\n",
      "281         1173         0\n",
      "282         1174         0\n",
      "283         1175         0\n",
      "284         1176         0\n",
      "285         1177         0\n",
      "286         1178         0\n",
      "287         1179         0\n",
      "288         1180         0\n",
      "289         1181         0\n",
      "290         1182         0\n",
      "291         1183         0\n",
      "292         1184         0\n",
      "293         1185         0\n",
      "294         1186         0\n",
      "295         1187         0\n",
      "296         1188         0\n",
      "297         1189         0\n",
      "298         1190         0\n",
      "299         1191         0\n",
      "300         1192         0\n",
      "301         1193         0\n",
      "302         1194         0\n",
      "303         1195         0\n",
      "304         1196         0\n",
      "305         1197         1\n",
      "306         1198         0\n",
      "307         1199         0\n",
      "308         1200         0\n",
      "309         1201         0\n",
      "310         1202         0\n",
      "311         1203         0\n",
      "312         1204         0\n",
      "313         1205         0\n",
      "314         1206         1\n",
      "315         1207         0\n",
      "316         1208         0\n",
      "317         1209         0\n",
      "318         1210         0\n",
      "319         1211         0\n",
      "320         1212         0\n",
      "321         1213         0\n",
      "322         1214         0\n",
      "323         1215         0\n",
      "324         1216         0\n",
      "325         1217         0\n",
      "326         1218         0\n",
      "327         1219         0\n",
      "328         1220         0\n",
      "329         1221         0\n",
      "330         1222         0\n",
      "331         1223         0\n",
      "332         1224         0\n",
      "333         1225         0\n",
      "334         1226         0\n",
      "335         1227         0\n",
      "336         1228         0\n",
      "337         1229         0\n",
      "338         1230         0\n",
      "339         1231         0\n",
      "340         1232         0\n",
      "341         1233         0\n",
      "342         1234         1\n",
      "343         1235         1\n",
      "344         1236         0\n",
      "345         1237         0\n",
      "346         1238         0\n",
      "347         1239         0\n",
      "348         1240         0\n",
      "349         1241         0\n",
      "350         1242         1\n",
      "351         1243         0\n",
      "352         1244         0\n",
      "353         1245         0\n",
      "354         1246         0\n",
      "355         1247         0\n",
      "356         1248         1\n",
      "357         1249         0\n",
      "358         1250         0\n",
      "359         1251         0\n",
      "360         1252         0\n",
      "361         1253         0\n",
      "362         1254         0\n",
      "363         1255         0\n",
      "364         1256         1\n",
      "365         1257         1\n",
      "366         1258         0\n",
      "367         1259         0\n",
      "368         1260         1\n",
      "369         1261         0\n",
      "370         1262         0\n",
      "371         1263         1\n",
      "372         1264         0\n",
      "373         1265         0\n",
      "374         1266         1\n",
      "375         1267         1\n",
      "376         1268         0\n",
      "377         1269         0\n",
      "378         1270         0\n",
      "379         1271         0\n",
      "380         1272         0\n",
      "381         1273         0\n",
      "382         1274         0\n",
      "383         1275         0\n",
      "384         1276         0\n",
      "385         1277         0\n",
      "386         1278         0\n",
      "387         1279         0\n",
      "388         1280         0\n",
      "389         1281         0\n",
      "390         1282         0\n",
      "391         1283         0\n",
      "392         1284         0\n",
      "393         1285         0\n",
      "394         1286         0\n",
      "395         1287         1\n",
      "396         1288         0\n",
      "397         1289         1\n",
      "398         1290         0\n",
      "399         1291         0\n",
      "400         1292         0\n",
      "401         1293         0\n",
      "402         1294         1\n",
      "403         1295         0\n",
      "404         1296         0\n",
      "405         1297         0\n",
      "406         1298         0\n",
      "407         1299         0\n",
      "408         1300         0\n",
      "409         1301         0\n",
      "410         1302         0\n",
      "411         1303         1\n",
      "412         1304         0\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         0\n"
     ]
    }
   ],
   "source": [
    "passenger_ids = test_set['PassengerId']\n",
    "y_pred_df= pd.DataFrame(y_pred, columns=['survived'])\n",
    "y_pred = y_pred_df['survived']\n",
    "result = pd.DataFrame({'PassengerId':passenger_ids, 'Survived':y_pred})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8866 - loss: 0.4296\n",
      "Test Accuracy: 0.8899521827697754\n",
      "Test Loss: 0.4306966960430145\n"
     ]
    }
   ],
   "source": [
    "# Extract ground truth labels for the test set\n",
    "y_test = Y_test['Survived']\n",
    "\n",
    "# Evaluate the model's performance on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Print the test loss\n",
    "print(f\"Test Loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves the DataFrame result to a CSV file named 'Y_pred.csv'\n",
    "result.to_csv(r'C:\\Users\\Hp\\OneDrive\\Desktop\\Kaggle work\\titanic\\Y_pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
